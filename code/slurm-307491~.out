@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
probing_case 도입


@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ RUNNING SCRIPT: job_n_NoAug_py_codebert_syn.sh

Wed Mar 22 17:05:05 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |
| 30%   28C    P8    20W / 350W |      1MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Jun__8_16:49:14_PDT_2022
Cuda compilation tools, release 11.7, V11.7.99
Build cuda_11.7.r11.7/compiler.31442593_0
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ START TRAIN @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Source: desc Target: python
Data path: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/
Pre-trained model: microsoft/codebert-base
Model type: roberta
Experiment name: codebert_nl_pl_program
TEST_FILE_SRC: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt TEST_FILE_TGT: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
/home/ysnamgoong42/ws/XLCoST/code
03/22/2023 17:05:09 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/codebert-base', dev_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/val-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/val-Python-desc-tok.py', do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_batch_size=16, eval_steps=2500, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=10.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename=None, tokenizer_name='microsoft/codebert-base', train_batch_size=16, train_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/train-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/train-Python-desc-tok.py', train_steps=5000, warmup_steps=0, weight_decay=0.0)
03/22/2023 17:05:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/22/2023 17:05:19 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:19 - INFO - __main__ -   idx: 0
03/22/2023 17:05:19 - INFO - __main__ -   source_tokens: ['<s>', 'Maximum', '_Pre', 'fix', '_Sum', '_possible', '_by', '_merging', '_two', '_given', '_arrays', '_|', '_Python', '3', '_implementation', '_of', '_the', '_above', '_approach', '_;', '_Stores', '_the', '_maximum', '_prefix', '_sum', '_of', '_the', '_array', '_A', '_[', '_]', '_;', '_Tra', 'verse', '_the', '_array', '_A', '_[', '_]', '_;', '_Stores', '_the', '_maximum', '_prefix', '_sum', '_of', '_the', '_array', '_B', '_[', '_]', '_;', '_Tra', 'verse', '_the', '_array', '_B', '_[', '_]', '_;', '_Driver', '_code', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   source_ids: 0 48089 5048 23032 9430 678 30 29002 80 576 42156 1721 31886 246 5574 9 5 1065 1548 25606 19225 5 4532 46622 6797 9 5 8932 83 646 27779 25606 8221 15189 5 8932 83 646 27779 25606 19225 5 4532 46622 6797 9 5 8932 163 646 27779 25606 8221 15189 5 8932 163 646 27779 25606 16870 3260 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   target_tokens: ['<s>', 'def', '_max', 'Pres', 'um', '_(', '_a', '_,', '_b', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_X', '_=', '_max', '_(', '_a', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_a', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_a', '_[', '_i', '_]', '_+=', '_a', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_X', '_=', '_max', '_(', '_X', '_,', '_a', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_Y', '_=', '_max', '_(', '_b', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_b', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_b', '_[', '_i', '_]', '_+=', '_b', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_Y', '_=', '_max', '_(', '_Y', '_,', '_b', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_return', '_X', '_+', '_Y', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_A', '_=', '_[', '_2', '_,', '_-', '_1', '_,', '_4', '_,', '_-', '_5', '_]', '_NEW', '_', 'LINE', '_B', '_=', '_[', '_4', '_,', '_-', '_3', '_,', '_12', '_,', '_4', '_,', '_-', '_3', '_]', '_NEW', '_', 'LINE', '_print', '_(', '_max', 'Pres', 'um', '_(', '_A', '_,', '_B', '_)', '_)', '_NEW', '_', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   target_ids: 0 9232 19220 28917 783 36 10 2156 741 4839 4832 5178 1215 28302 12569 5382 1577 5457 19220 36 10 646 321 27779 2156 321 4839 5178 1215 28302 13 939 11 1186 36 112 2156 25528 36 10 4839 4839 4832 5178 1215 28302 12569 5382 10 646 939 27779 49371 10 646 939 111 112 27779 5178 1215 28302 1577 5457 19220 36 1577 2156 10 646 939 27779 4839 5178 1215 28302 211 1691 5382 854 5457 19220 36 741 646 321 27779 2156 321 4839 5178 1215 28302 13 939 11 1186 36 112 2156 25528 36 741 4839 4839 4832 5178 1215 28302 12569 5382 741 646 939 27779 49371 741 646 939 111 112 27779 5178 1215 28302 854 5457 19220 36 854 2156 741 646 939 27779 4839 5178 1215 28302 211 1691 5382 671 1577 2055 854 5178 1215 28302 211 1691 5382 83 5457 646 132 2156 111 112 2156 204 2156 111 195 27779 5178 1215 28302 163 5457 646 204 2156 111 155 2156 316 2156 204 2156 111 155 27779 5178 1215 28302 5780 36 19220 28917 783 36 83 2156 163 4839 4839 5178 1215 2
03/22/2023 17:05:19 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:19 - INFO - __main__ -   idx: 1
03/22/2023 17:05:19 - INFO - __main__ -   source_tokens: ['<s>', 'Check', '_if', '_a', '_number', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_positive', '_perfect', '_cubes', '_|', '_Python', '3', '_program', '_for', '_the', '_above', '_approach', '_;', '_Function', '_to', '_check', '_if', '_N', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_perfect', '_cubes', '_or', '_not', '_;', '_If', '_it', '_is', '_same', '_return', '_true', '_;', '_;', '_If', '_the', '_cur', 'r', '_smaller', '_than', '_n', '_increment', '_the', '_lo', '_;', '_If', '_the', '_cur', 'r', '_is', '_greater', '_than', '_cur', 'r', '_decre', 'ment', '_the', '_hi', '_;', '_Driver', '_Code', '_;', '_Function', '_call', '_to', '_check', '_if', '_N', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_perfect', '_cubes', '_or', '_not', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   source_ids: 0 26615 114 10 346 64 28 4625 25 6797 9 80 1313 1969 35788 1721 31886 246 586 13 5 1065 1548 25606 42419 7 1649 114 234 64 28 4625 25 6797 9 80 1969 35788 50 45 25606 318 24 16 276 671 1528 25606 25606 318 5 5350 338 2735 87 295 30401 5 4600 25606 318 5 5350 338 16 2388 87 5350 338 33186 1757 5 20280 25606 16870 8302 25606 42419 486 7 1649 114 234 64 28 4625 25 6797 9 80 1969 35788 50 45 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   target_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_lo', '_=', '_1', '_NEW', '_', 'LINE', '_hi', '_=', '_round', '_(', '_math', '_.', '_pow', '_(', '_n', '_,', '_1', '_/', '_3', '_)', '_)', '_NEW', '_', 'LINE', '_while', '_(', '_lo', '_<=', '_hi', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_cur', 'r', '_=', '_(', '_lo', '_*', '_lo', '_*', '_lo', '_+', '_hi', '_*', '_hi', '_*', '_hi', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_cur', 'r', '_==', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_True', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_cur', 'r', '_<', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_lo', '_+=', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_else', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_hi', '_-=', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_return', '_False', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_N', '_=', '_28', '_NEW', '_', 'LINE', '_if', '_(', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_N', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_print', '_(', '_"', '_True', '_"', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_else', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_print', '_(', '_"', '_False', '_"', '_)', '_NEW', '_', 'LINE', '_D', 'ED', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   target_ids: 0 41975 10638 5178 1215 28302 3816 6797 10643 9058 347 39749 36 295 4839 4832 5178 1215 28302 12569 5382 4600 5457 112 5178 1215 28302 20280 5457 1062 36 10638 479 30964 36 295 2156 112 1589 155 4839 4839 5178 1215 28302 150 36 4600 49230 20280 4839 4832 5178 1215 28302 12569 5382 5350 338 5457 36 4600 1009 4600 1009 4600 2055 20280 1009 20280 1009 20280 4839 5178 1215 28302 114 36 5350 338 45994 295 4839 4832 5178 1215 28302 12569 5382 671 7447 5178 1215 28302 211 1691 5382 114 36 5350 338 28696 295 4839 4832 5178 1215 28302 12569 5382 4600 49371 112 5178 1215 28302 211 1691 5382 1493 4832 5178 1215 28302 12569 5382 20280 49826 112 5178 1215 28302 211 1691 5382 211 1691 5382 671 35297 5178 1215 28302 211 1691 5382 234 5457 971 5178 1215 28302 114 36 6797 10643 9058 347 39749 36 234 4839 4839 4832 5178 1215 28302 12569 5382 5780 36 22 7447 22 4839 5178 1215 28302 211 1691 5382 1493 4832 5178 1215 28302 12569 5382 5780 36 22 35297 22 4839 5178 1215 28302 211 1691 2
03/22/2023 17:05:19 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:19 - INFO - __main__ -   idx: 2
03/22/2023 17:05:19 - INFO - __main__ -   source_tokens: ['<s>', 'Gener', 'ate', '_an', '_N', '_|', '_Python', '3', '_program', '_for', '_the', '_above', '_approach', '_;', '_Function', '_to', '_generate', '_all', '_prime', '_numbers', '_upt', 'o', '_10', '_^', '_6', '_;', '_Initial', 'ize', '_s', 'ieve', '_[', '_]', '_as', '_1', '_;', '_Iter', 'ate', '_over', '_the', '_range', '_[', '_2', '_,', '_N', '_]', '_;', '_If', '_current', '_element', '_is', '_non', '_-', '_prime', '_;', '_Make', '_all', '_multi', 'ples', '_of', '_i', '_as', '_0', '_;', '_Function', '_to', '_construct', '_an', '_array', '_A', '_[', '_]', '_satisfying', '_the', '_given', '_conditions', '_;', '_Stores', '_the', '_resultant', '_array', '_;', '_Stores', '_all', '_prime', '_numbers', '_;', '_S', 'ieve', '_of', '_Er', 'ast', 'ost', 'hen', 'es', '_;', '_App', 'end', '_the', '_integer', '_i', '_if', '_it', '_is', '_a', '_prime', '_;', '_Ind', 'icates', '_current', '_position', '_in', '_list', '_of', '_prime', '_numbers', '_;', '_Tra', 'verse', '_the', '_array', '_arr', '_[', '_]', '_;', '_If', '_already', '_filled', '_with', '_another', '_prime', '_number', '_;', '_If', '_A', '_[', '_i', '_]', '_is', '_not', '_filled', '_but', '_A', '_[', '_ind', '_]', '_is', '_filled', '_;', '_Store', '_A', '_[', '_i', '_]', '_=', '_A', '_[', '_ind', '_]', '_;', '_If', '_none', '_of', '_them', '_were', '_filled', '_;', '_To', '_make', '_sure', '_A', '_[', '_i', '_]', '_does', '_not', '_affect', '_other', '_values', '_,', '_store', '_next', '_prime', '_number', '_;', '_Print', '_the', '_resultant', '_array', '_;', '_Driver', '_Code', '_;', '_Function', '_Call', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   source_ids: 0 40025 877 41 234 1721 31886 246 586 13 5 1065 1548 25606 42419 7 5368 70 2654 1530 18256 139 158 37249 231 25606 24685 2072 579 16637 646 27779 25 112 25606 47476 877 81 5 1186 646 132 2156 234 27779 25606 318 595 7510 16 786 111 2654 25606 5293 70 3228 12349 9 939 25 321 25606 42419 7 12558 41 8932 83 646 27779 17758 5 576 1274 25606 19225 5 41474 8932 25606 19225 70 2654 1530 25606 208 16637 9 4594 1988 2603 2457 293 25606 3166 1397 5 48335 939 114 24 16 10 2654 25606 4619 23020 595 737 11 889 9 2654 1530 25606 8221 15189 5 8932 25743 646 27779 25606 318 416 3820 19 277 2654 346 25606 318 83 646 939 27779 16 45 3820 53 83 646 9473 27779 16 3820 25606 7248 83 646 939 27779 5457 83 646 9473 27779 25606 318 4146 9 106 58 3820 25606 598 146 686 83 646 939 27779 473 45 3327 97 3266 2156 1400 220 2654 346 25606 6883 5 41474 8932 25606 16870 8302 25606 42419 3310 2 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   target_tokens: ['<s>', 's', 'ieve', '_=', '_[', '_1', '_]', '_*', '_(', '_100', '0000', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_def', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_N', '_=', '_100', '0000', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_N', '_+', '_1', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_if', '_i', '_*', '_i', '_>', '_N', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_break', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_s', 'ieve', '_[', '_i', '_]', '_==', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_continue', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_for', '_j', '_in', '_range', '_(', '_i', '_*', '_i', '_,', '_N', '_+', '_1', '_,', '_i', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_s', 'ieve', '_[', '_j', '_]', '_=', '_0', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_def', '_get', 'Array', '_(', '_arr', '_,', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_A', '_=', '_[', '_0', '_]', '_*', '_N', '_NEW', '_', 'LINE', '_v', '_=', '_[', '_]', '_NEW', '_', 'LINE', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_int', '_(', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   target_ids: 0 29 16637 5457 646 112 27779 1009 36 727 14200 2055 112 4839 5178 1215 28302 3816 579 16637 10643 21077 9452 36 4839 4832 5178 1215 28302 12569 5382 720 579 16637 5178 1215 28302 234 5457 727 14200 5178 1215 28302 13 939 11 1186 36 132 2156 234 2055 112 4839 4832 5178 1215 28302 12569 5382 114 939 1009 939 8061 234 4832 5178 1215 28302 12569 5382 1108 5178 1215 28302 211 1691 5382 114 36 579 16637 646 939 27779 45994 321 4839 4832 5178 1215 28302 12569 5382 535 5178 1215 28302 211 1691 5382 13 1236 11 1186 36 939 1009 939 2156 234 2055 112 2156 939 4839 4832 5178 1215 28302 12569 5382 579 16637 646 1236 27779 5457 321 5178 1215 28302 211 1691 5382 211 1691 5382 211 1691 5382 3816 120 48222 36 25743 2156 234 4839 4832 5178 1215 28302 12569 5382 720 579 16637 5178 1215 28302 83 5457 646 321 27779 1009 234 5178 1215 28302 748 5457 646 27779 5178 1215 28302 579 16637 10643 21077 9452 36 4839 5178 1215 28302 13 939 11 1186 36 132 2156 6979 36 2
03/22/2023 17:05:19 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:19 - INFO - __main__ -   idx: 3
03/22/2023 17:05:19 - INFO - __main__ -   source_tokens: ['<s>', 'N', 'th', '_natural', '_number', '_after', '_removing', '_all', '_numbers', '_consisting', '_of', '_the', '_digit', '_9', '_|', '_Function', '_to', '_find', '_N', 'th', '_number', '_in', '_base', '_9', '_;', '_Stores', '_the', '_N', 'th', '_number', '_;', '_Iter', 'ate', '_while', '_N', '_is', '_greater', '_than', '_0', '_;', '_Update', '_result', '_;', '_Divide', '_N', '_by', '_9', '_;', '_Mult', 'ip', 'ly', '_p', '_by', '_10', '_;', '_Return', '_result', '_;', '_Driver', '_Code', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   source_ids: 0 487 212 1632 346 71 8201 70 1530 17402 9 5 16808 361 1721 42419 7 465 234 212 346 11 1542 361 25606 19225 5 234 212 346 25606 47476 877 150 234 16 2388 87 321 25606 14686 898 25606 39030 234 30 361 25606 14910 1588 352 181 30 158 25606 11968 898 25606 16870 8302 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   target_tokens: ['<s>', 'def', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_result', '_=', '_0', '_NEW', '_', 'LINE', '_p', '_=', '_1', '_NEW', '_', 'LINE', '_while', '_(', '_N', '_>', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_result', '_+=', '_(', '_p', '_*', '_(', '_N', '_%', '_9', '_)', '_)', '_NEW', '_', 'LINE', '_N', '_=', '_N', '_//', '_9', '_NEW', '_', 'LINE', '_p', '_=', '_p', '_*', '_10', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_return', '_result', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '___', 'name', '__', '_==', "_'", '__', '__', '_main', '__', '__', "_'", '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_N', '_=', '_9', '_NEW', '_', 'LINE', '_print', '_(', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   target_ids: 0 9232 465 487 212 43623 36 234 4839 4832 5178 1215 28302 12569 5382 898 5457 321 5178 1215 28302 181 5457 112 5178 1215 28302 150 36 234 8061 321 4839 4832 5178 1215 28302 12569 5382 898 49371 36 181 1009 36 234 7606 361 4839 4839 5178 1215 28302 234 5457 234 21277 361 5178 1215 28302 181 5457 181 1009 158 5178 1215 28302 211 1691 5382 671 898 5178 1215 28302 211 1691 5382 114 27148 13650 30529 45994 128 18134 18134 1049 18134 18134 128 4832 5178 1215 28302 12569 5382 234 5457 361 5178 1215 28302 5780 36 465 487 212 43623 36 234 4839 4839 5178 1215 28302 211 1691 5382 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:19 - INFO - __main__ -   idx: 4
03/22/2023 17:05:19 - INFO - __main__ -   source_tokens: ['<s>', 'Check', '_if', '_an', '_integer', '_is', '_rotation', '_of', '_another', '_given', '_integer', '_|', '_Python', '3', '_implementation', '_of', '_the', '_approach', '_;', '_Function', '_to', '_check', '_if', '_the', '_integer', '_A', '_is', '_a', '_rotation', '_of', '_the', '_integer', '_B', '_;', '_Stores', '_the', '_count', '_of', '_digits', '_in', '_A', '_;', '_Stores', '_the', '_count', '_of', '_digits', '_in', '_B', '_;', '_If', '_dig', '1', '_not', '_equal', '_to', '_dig', '2', '_;', '_Stores', '_position', '_of', '_first', '_digit', '_;', '_Stores', '_the', '_first', '_digit', '_;', '_Rot', 'ate', '_the', '_digits', '_of', '_the', '_integer', '_;', '_If', '_A', '_is', '_equal', '_to', '_B', '_;', '_If', '_A', '_is', '_equal', '_to', '_the', '_initial', '_value', '_of', '_integer', '_A', '_;', '_Driver', '_code', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   source_ids: 0 26615 114 41 48335 16 10134 9 277 576 48335 1721 31886 246 5574 9 5 1548 25606 42419 7 1649 114 5 48335 83 16 10 10134 9 5 48335 163 25606 19225 5 3212 9 15769 11 83 25606 19225 5 3212 9 15769 11 163 25606 318 8512 134 45 3871 7 8512 176 25606 19225 737 9 78 16808 25606 19225 5 78 16808 25606 9104 877 5 15769 9 5 48335 25606 318 83 16 3871 7 163 25606 318 83 16 3871 7 5 2557 923 9 48335 83 25606 16870 3260 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:19 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:19 - INFO - __main__ -   target_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_check', '_(', '_A', '_,', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_dig', '1', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_A', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_dig', '2', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_B', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_dig', '1', '_!=', '_dig', '2', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_0', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_temp', '_=', '_A', '_NEW', '_', 'LINE', '_while', '_(', '_True', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_power', '_=', '_pow', '_(', '_10', '_,', '_dig', '1', '_-', '_1', '_)', '_NEW', '_', 'LINE', '_first', 'digit', '_=', '_A', '_//', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_-', '_first', 'digit', '_*', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_*', '_10', '_+', '_first', 'digit', '_NEW', '_', 'LINE', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_A', '_==', '_temp', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_0', '_NEW', '_', 'LINE', '</s>']
03/22/2023 17:05:19 - INFO - __main__ -   target_ids: 0 41975 10638 5178 1215 28302 3816 1649 36 83 2156 163 4839 4832 5178 1215 28302 12569 5382 114 36 83 45994 163 4839 4832 5178 1215 28302 12569 5382 671 112 5178 1215 28302 211 1691 5382 8512 134 5457 10638 479 1929 36 10638 479 7425 698 36 83 4839 2055 112 4839 5178 1215 28302 8512 176 5457 10638 479 1929 36 10638 479 7425 698 36 163 4839 2055 112 4839 5178 1215 28302 114 36 8512 134 49333 8512 176 4839 4832 5178 1215 28302 12569 5382 671 321 5178 1215 28302 211 1691 5382 32196 5457 83 5178 1215 28302 150 36 7447 4839 4832 5178 1215 28302 12569 5382 476 5457 30964 36 158 2156 8512 134 111 112 4839 5178 1215 28302 78 10289 5457 83 21277 476 5178 1215 28302 83 5457 83 111 78 10289 1009 476 5178 1215 28302 83 5457 83 1009 158 2055 78 10289 5178 1215 28302 114 36 83 45994 163 4839 4832 5178 1215 28302 12569 5382 671 112 5178 1215 28302 211 1691 5382 114 36 83 45994 32196 4839 4832 5178 1215 28302 12569 5382 671 321 5178 1215 28302 2
03/22/2023 17:05:19 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/home/ysnamgoong42/miniconda3/envs/xlcost/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/22/2023 17:05:32 - INFO - __main__ -   ***** Running training *****
03/22/2023 17:05:32 - INFO - __main__ -     Num examples = 9263
03/22/2023 17:05:32 - INFO - __main__ -     Batch size = 16
03/22/2023 17:05:32 - INFO - __main__ -     Num epoch = 9
03/22/2023 17:05:59 - INFO - __main__ -     step 100 loss 3.4233
03/22/2023 17:06:26 - INFO - __main__ -     step 200 loss 2.8495
03/22/2023 17:06:53 - INFO - __main__ -     step 300 loss 2.562
03/22/2023 17:07:20 - INFO - __main__ -     step 400 loss 2.3712
03/22/2023 17:07:47 - INFO - __main__ -     step 500 loss 2.2315
03/22/2023 17:08:13 - INFO - __main__ -     step 600 loss 2.1204
03/22/2023 17:08:42 - INFO - __main__ -     step 700 loss 2.032
03/22/2023 17:09:09 - INFO - __main__ -     step 800 loss 1.9581
03/22/2023 17:09:36 - INFO - __main__ -     step 900 loss 1.8939
03/22/2023 17:10:02 - INFO - __main__ -     step 1000 loss 1.841
03/22/2023 17:10:29 - INFO - __main__ -     step 1100 loss 1.794
03/22/2023 17:10:45 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:10:45 - INFO - __main__ -     Num examples = 472
03/22/2023 17:10:45 - INFO - __main__ -     Batch size = 16
03/22/2023 17:10:47 - INFO - __main__ -     eval_ppl = 3.45286
03/22/2023 17:10:47 - INFO - __main__ -     global_step = 1157
03/22/2023 17:10:47 - INFO - __main__ -     train_loss = 1.7681
03/22/2023 17:10:47 - INFO - __main__ -     ********************
03/22/2023 17:10:50 - INFO - __main__ -     Best ppl:3.45286
03/22/2023 17:10:50 - INFO - __main__ -     ********************
03/22/2023 17:20:26 - INFO - __main__ -     bleu-4 = 15.81 
03/22/2023 17:20:26 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:20:26 - INFO - __main__ -     ********************
03/22/2023 17:20:26 - INFO - __main__ -     Best bleu:15.81
03/22/2023 17:20:26 - INFO - __main__ -     ********************
03/22/2023 17:20:40 - INFO - __main__ -     step 1200 loss 1.297
03/22/2023 17:21:07 - INFO - __main__ -     step 1300 loss 1.2573
03/22/2023 17:21:34 - INFO - __main__ -     step 1400 loss 1.2417
03/22/2023 17:22:01 - INFO - __main__ -     step 1500 loss 1.2264
03/22/2023 17:22:27 - INFO - __main__ -     step 1600 loss 1.2153
03/22/2023 17:22:54 - INFO - __main__ -     step 1700 loss 1.2028
03/22/2023 17:23:21 - INFO - __main__ -     step 1800 loss 1.1899
03/22/2023 17:23:47 - INFO - __main__ -     step 1900 loss 1.1773
03/22/2023 17:24:14 - INFO - __main__ -     step 2000 loss 1.1664
03/22/2023 17:24:41 - INFO - __main__ -     step 2100 loss 1.1553
03/22/2023 17:25:07 - INFO - __main__ -     step 2200 loss 1.1456
03/22/2023 17:25:34 - INFO - __main__ -     step 2300 loss 1.1352
03/22/2023 17:25:38 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:25:38 - INFO - __main__ -     Num examples = 472
03/22/2023 17:25:38 - INFO - __main__ -     Batch size = 16
03/22/2023 17:25:40 - INFO - __main__ -     eval_ppl = 2.86917
03/22/2023 17:25:40 - INFO - __main__ -     global_step = 2314
03/22/2023 17:25:40 - INFO - __main__ -     train_loss = 1.1338
03/22/2023 17:25:40 - INFO - __main__ -     ********************
03/22/2023 17:25:44 - INFO - __main__ -     Best ppl:2.86917
03/22/2023 17:25:44 - INFO - __main__ -     ********************
03/22/2023 17:35:18 - INFO - __main__ -     bleu-4 = 18.39 
03/22/2023 17:35:18 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:35:18 - INFO - __main__ -     ********************
03/22/2023 17:35:18 - INFO - __main__ -     Best bleu:18.39
03/22/2023 17:35:18 - INFO - __main__ -     ********************
03/22/2023 17:35:44 - INFO - __main__ -     step 2400 loss 1.0151
03/22/2023 17:36:10 - INFO - __main__ -     step 2500 loss 1.0036
03/22/2023 17:36:37 - INFO - __main__ -     step 2600 loss 0.9988
03/22/2023 17:37:04 - INFO - __main__ -     step 2700 loss 0.9898
03/22/2023 17:37:30 - INFO - __main__ -     step 2800 loss 0.9838
03/22/2023 17:37:57 - INFO - __main__ -     step 2900 loss 0.976
03/22/2023 17:38:24 - INFO - __main__ -     step 3000 loss 0.9699
03/22/2023 17:38:51 - INFO - __main__ -     step 3100 loss 0.9629
03/22/2023 17:39:17 - INFO - __main__ -     step 3200 loss 0.9568
03/22/2023 17:39:44 - INFO - __main__ -     step 3300 loss 0.9507
03/22/2023 17:40:11 - INFO - __main__ -     step 3400 loss 0.9454
03/22/2023 17:40:30 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:40:30 - INFO - __main__ -     Num examples = 472
03/22/2023 17:40:30 - INFO - __main__ -     Batch size = 16
03/22/2023 17:40:32 - INFO - __main__ -     eval_ppl = 2.66353
03/22/2023 17:40:32 - INFO - __main__ -     global_step = 3471
03/22/2023 17:40:32 - INFO - __main__ -     train_loss = 0.9407
03/22/2023 17:40:32 - INFO - __main__ -     ********************
03/22/2023 17:40:35 - INFO - __main__ -     Best ppl:2.66353
03/22/2023 17:40:35 - INFO - __main__ -     ********************
03/22/2023 17:49:51 - INFO - __main__ -     bleu-4 = 19.11 
03/22/2023 17:49:51 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:49:51 - INFO - __main__ -     ********************
03/22/2023 17:49:51 - INFO - __main__ -     Best bleu:19.11
03/22/2023 17:49:51 - INFO - __main__ -     ********************
03/22/2023 17:50:02 - INFO - __main__ -     step 3500 loss 0.8962
03/22/2023 17:50:29 - INFO - __main__ -     step 3600 loss 0.8691
03/22/2023 17:50:55 - INFO - __main__ -     step 3700 loss 0.8664
03/22/2023 17:51:22 - INFO - __main__ -     step 3800 loss 0.8608
03/22/2023 17:51:49 - INFO - __main__ -     step 3900 loss 0.8569
03/22/2023 17:52:15 - INFO - __main__ -     step 4000 loss 0.8535
03/22/2023 17:52:42 - INFO - __main__ -     step 4100 loss 0.8484
03/22/2023 17:53:09 - INFO - __main__ -     step 4200 loss 0.8433
03/22/2023 17:53:35 - INFO - __main__ -     step 4300 loss 0.8397
03/22/2023 17:54:02 - INFO - __main__ -     step 4400 loss 0.8351
03/22/2023 17:54:29 - INFO - __main__ -     step 4500 loss 0.8322
03/22/2023 17:54:55 - INFO - __main__ -     step 4600 loss 0.8286
03/22/2023 17:55:03 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:55:03 - INFO - __main__ -     Num examples = 472
03/22/2023 17:55:03 - INFO - __main__ -     Batch size = 16
03/22/2023 17:55:05 - INFO - __main__ -     eval_ppl = 2.57192
03/22/2023 17:55:05 - INFO - __main__ -     global_step = 4628
03/22/2023 17:55:05 - INFO - __main__ -     train_loss = 0.8273
03/22/2023 17:55:05 - INFO - __main__ -     ********************
03/22/2023 17:55:09 - INFO - __main__ -     Best ppl:2.57192
03/22/2023 17:55:09 - INFO - __main__ -     ********************
03/22/2023 18:04:28 - INFO - __main__ -     bleu-4 = 19.71 
03/22/2023 18:04:28 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:04:28 - INFO - __main__ -     ********************
03/22/2023 18:04:28 - INFO - __main__ -     Best bleu:19.71
03/22/2023 18:04:28 - INFO - __main__ -     ********************
03/22/2023 18:04:56 - INFO - __main__ -     step 4700 loss 0.7883
03/22/2023 18:05:23 - INFO - __main__ -     step 4800 loss 0.78
03/22/2023 18:05:50 - INFO - __main__ -     step 4900 loss 0.7808
03/22/2023 18:06:17 - INFO - __main__ -     step 5000 loss 0.7776
03/22/2023 18:06:44 - INFO - __main__ -     step 5100 loss 0.7754
03/22/2023 18:07:11 - INFO - __main__ -     step 5200 loss 0.7729
03/22/2023 18:07:37 - INFO - __main__ -     step 5300 loss 0.7708
03/22/2023 18:08:04 - INFO - __main__ -     step 5400 loss 0.7683
03/22/2023 18:08:31 - INFO - __main__ -     step 5500 loss 0.7672
03/22/2023 18:08:57 - INFO - __main__ -     step 5600 loss 0.7648
03/22/2023 18:09:24 - INFO - __main__ -     step 5700 loss 0.7635
03/22/2023 18:09:46 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 18:09:46 - INFO - __main__ -     Num examples = 472
03/22/2023 18:09:46 - INFO - __main__ -     Batch size = 16
03/22/2023 18:09:49 - INFO - __main__ -     eval_ppl = 2.53494
03/22/2023 18:09:49 - INFO - __main__ -     global_step = 5785
03/22/2023 18:09:49 - INFO - __main__ -     train_loss = 0.7617
03/22/2023 18:09:49 - INFO - __main__ -     ********************
03/22/2023 18:09:52 - INFO - __main__ -     Best ppl:2.53494
03/22/2023 18:09:52 - INFO - __main__ -     ********************
03/22/2023 18:19:18 - INFO - __main__ -     bleu-4 = 20.4 
03/22/2023 18:19:18 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:19:18 - INFO - __main__ -     ********************
03/22/2023 18:19:18 - INFO - __main__ -     Best bleu:20.4
03/22/2023 18:19:18 - INFO - __main__ -     ********************
03/22/2023 18:19:26 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/codebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=16, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py', tokenizer_name='microsoft/codebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
03/22/2023 18:19:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/22/2023 18:19:34 - INFO - __main__ -   reload model from /home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin
03/22/2023 18:19:37 - INFO - __main__ -   Test file: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
  0%|          | 0/56 [00:00<?, ?it/s]  2%|▏         | 1/56 [00:20<18:22, 20.04s/it]  4%|▎         | 2/56 [00:37<16:54, 18.79s/it]  5%|▌         | 3/56 [00:55<16:06, 18.23s/it]  7%|▋         | 4/56 [01:13<15:50, 18.28s/it]  9%|▉         | 5/56 [01:31<15:21, 18.06s/it] 11%|█         | 6/56 [01:46<14:11, 17.04s/it] 12%|█▎        | 7/56 [02:06<14:33, 17.83s/it] 14%|█▍        | 8/56 [02:26<14:58, 18.72s/it] 16%|█▌        | 9/56 [02:48<15:26, 19.71s/it] 18%|█▊        | 10/56 [03:06<14:38, 19.10s/it] 20%|█▉        | 11/56 [03:23<13:49, 18.43s/it] 21%|██▏       | 12/56 [03:41<13:23, 18.26s/it] 23%|██▎       | 13/56 [03:59<13:04, 18.25s/it] 25%|██▌       | 14/56 [04:19<13:09, 18.80s/it] 27%|██▋       | 15/56 [04:41<13:37, 19.93s/it] 29%|██▊       | 16/56 [05:01<13:09, 19.75s/it] 30%|███       | 17/56 [05:20<12:42, 19.55s/it] 32%|███▏      | 18/56 [05:36<11:49, 18.66s/it] 34%|███▍      | 19/56 [05:56<11:42, 18.98s/it] 36%|███▌      | 20/56 [06:17<11:45, 19.60s/it] 38%|███▊      | 21/56 [06:38<11:40, 20.02s/it] 39%|███▉      | 22/56 [06:53<10:24, 18.38s/it] 41%|████      | 23/56 [07:14<10:32, 19.17s/it] 43%|████▎     | 24/56 [07:35<10:29, 19.66s/it] 45%|████▍     | 25/56 [07:53<10:01, 19.39s/it] 46%|████▋     | 26/56 [08:15<10:00, 20.01s/it] 48%|████▊     | 27/56 [08:35<09:42, 20.08s/it] 50%|█████     | 28/56 [08:54<09:13, 19.78s/it] 52%|█████▏    | 29/56 [09:13<08:48, 19.57s/it] 54%|█████▎    | 30/56 [09:32<08:20, 19.26s/it] 55%|█████▌    | 31/56 [09:53<08:18, 19.94s/it] 57%|█████▋    | 32/56 [10:14<08:05, 20.23s/it] 59%|█████▉    | 33/56 [10:33<07:33, 19.73s/it] 61%|██████    | 34/56 [10:52<07:08, 19.48s/it] 62%|██████▎   | 35/56 [11:12<06:51, 19.62s/it] 64%|██████▍   | 36/56 [11:31<06:29, 19.48s/it] 66%|██████▌   | 37/56 [11:48<05:55, 18.72s/it] 68%|██████▊   | 38/56 [12:02<05:14, 17.48s/it] 70%|██████▉   | 39/56 [12:21<05:04, 17.94s/it] 71%|███████▏  | 40/56 [12:40<04:51, 18.25s/it] 73%|███████▎  | 41/56 [12:55<04:16, 17.08s/it] 75%|███████▌  | 42/56 [13:10<03:52, 16.58s/it] 77%|███████▋  | 43/56 [13:27<03:37, 16.76s/it] 79%|███████▊  | 44/56 [13:45<03:25, 17.16s/it] 80%|████████  | 45/56 [14:01<03:03, 16.65s/it] 82%|████████▏ | 46/56 [14:17<02:46, 16.68s/it] 84%|████████▍ | 47/56 [14:33<02:28, 16.46s/it] 86%|████████▌ | 48/56 [14:50<02:12, 16.52s/it] 88%|████████▊ | 49/56 [15:05<01:51, 15.92s/it] 89%|████████▉ | 50/56 [15:22<01:38, 16.38s/it] 91%|█████████ | 51/56 [15:38<01:20, 16.12s/it] 93%|█████████▎| 52/56 [15:55<01:06, 16.51s/it] 95%|█████████▍| 53/56 [16:14<00:51, 17.27s/it] 96%|█████████▋| 54/56 [16:34<00:36, 18.06s/it] 98%|█████████▊| 55/56 [16:54<00:18, 18.72s/it]100%|██████████| 56/56 [17:03<00:00, 15.86s/it]100%|██████████| 56/56 [17:03<00:00, 18.28s/it]
03/22/2023 18:36:42 - INFO - __main__ -     bleu-4 = 21.55 
03/22/2023 18:36:42 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:36:42 - INFO - __main__ -     ********************
tokenizer.decode(t,: def minSum ( arr , N ) : NEW_LINE INDENT mp = { } NEW_LINE for i in range ( N ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if arr [ i ] in mp : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT else : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( minSum ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def getBinary ( n , k ) : NEW_LINE INDENT ans = 0 NEW_LINE while ( n > 0 ) : NEW_LINE INDENT n = n % 10 NEW_LINE n = n // 10 NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( 1 , n ) : NEW_LINE INDENT ans += ( n & ( 1 << i ) ) NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n , k ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans = ans [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n ) : NEW_LINE INDENT return ans NEW_LINE DED
tokenizer.decode(t,: from bisect import bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_right = bisect_right NEW_LINE bisect_right = bisect_left ( bisect_right , bisect_right , bisect_right ) NEW_LINE bisect_right = bisect_left ( bisect_right , bisect_right , bisect_right ) NEW_LINE for i in range ( len ( bisect_right ) ) : NEW_LINE INDENT for j in range ( len ( v ) ) : NEW_LINE INDENT if ( v [ i ] [ j ] == '1' ) : NEW_LINE INDENT v . append ( v [ i ] ) NEW_LINE DEDENT DEDENT DEDENT v . sort ( reverse ( ) ) NEW_LINE for i in range ( len ( v ) ) : NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def isValid ( x , y ) : NEW_LINE INDENT if ( x < y ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE D
tokenizer.decode(t,: from math import sqrt NEW_LINE def countRectangles ( X , Y ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( 1 , Y + 1 ) : NEW_LINE INDENT ans += ( Y * Y + Y ) NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT X = 5 NEW_LINE Y = 5 NEW_LINE print ( countRectangles ( X , Y ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def check ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT if ( s [ i ] != s [ i - 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = "11" NEW_LINE if ( check ( s ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: import math NEW_LINE def findKthBit ( n ) : NEW_LINE INDENT if ( n == 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT return - 1 NEW_LINE DEDENT n = 10 NEW_LINE print ( findKthBit ( n ) ) NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT printArr ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT arr = [ 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE printArr ( arr , n ) NEW_LINE
tokenizer.decode(t,: def findMissing ( arr , n ) : NEW_LINE INDENT for i in range ( 0 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i - 1 ] ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT DEDENT return - 1 NEW_LINE DEDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( findMissing ( arr , n ) ) NEW_LINE
tokenizer.decode(t,: MAX_CHAR = 26 NEW_LINE def lcs ( str1 , str2 ) : NEW_LINE INDENT lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE
tokenizer.decode(t,: def fact ( n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT print ( "1" ) NEW_LINE return NEW_LINE DEDENT else : NEW_LINE INDENT print ( "1" ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE print ( round ( n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: mod = 1000000007 NEW_LINE def power ( x , y ) : NEW_LINE INDENT if ( x == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT x = x * x NEW_LINE while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT x = y >> 1 NEW_LINE DEDENT y = y >> 1 NEW_LINE x = y >> 1 NEW_LINE DEDENT return x NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT x = y >> 1 NEW_LINE y = y >> 1 NEW_LINE DEDENT return x NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT if (
tokenizer.decode(t,: def countTriplets ( arr , N ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( N ) : NEW_LINE INDENT if ( arr [ i ] & 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 0 , 0 , 0 ] NEW_LINE N = len ( arr ) NEW_LINE countTriplets ( arr , N ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def areaArea ( area ) : NEW_LINE INDENT area = area * area NEW_LINE return area NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT area = 5 NEW_LINE print ( areaSquareArea ( area ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minimumSwaps ( A , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT else : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT DEDENT print ( ans ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ] NEW_LINE N = len ( A ) NEW_LINE minimumSwaps ( A , N ) NEW_LINE D
tokenizer.decode(t,: def lds ( arr , n ) : NEW_LINE INDENT lis = [ ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT lis [ i ] = arr [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT for j in range ( n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT return lis
tokenizer.decode(t,: def sumOfAP ( a , n ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT sum += a * a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT a = 2 NEW_LINE b = 2 NEW_LINE print ( sumOfAP ( a , n ) ) NEW_LINE
tokenizer.decode(t,: def sortArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE sortArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSquare ( a , b ) : NEW_LINE INDENT return a * b NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = 4 NEW_LINE print ( maxSquare ( a , b ) ) NEW_LINE DEDENT
tokenizer.decode(t,: MAX = 100 NEW_LINE def countWays ( mat , n , m ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( m ) : NEW_LINE INDENT for j in range ( m ) : NEW_LINE INDENT if ( mat [ i ] [ j ] == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT mat = [ [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 ] , [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ] , [ 1 , 1 , 1
tokenizer.decode(t,: dp = [ [ [ - 1 for i in range ( 100 ) ] for j in range ( 100 ) ] NEW_LINE def countPaths ( n , k ) : NEW_LINE INDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( countPaths ( n , k ) ) : NEW_LINE INDENT
tokenizer.decode(t,: def setBits ( a , b ) : NEW_LINE INDENT if ( a & b ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT a = b >> 1 NEW_LINE b = a >> 1 NEW_LINE while ( b ) : NEW_LINE INDENT a = b & b NEW_LINE b = b >> 1 NEW_LINE DEDENT return a NEW_LINE DEDENT a = 10 NEW_LINE b = 10 NEW_LINE print ( " Sum ▁ of ▁ of ▁ of ▁ of ▁ of ▁ is ▁ of ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ " , b = " , " , " , " , " , " , " , " , " , " , "
tokenizer.decode(t,: def findXOR ( arr , n ) : NEW_LINE INDENT prefixXor = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT return prefixXor ; NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] ; NEW_LINE n = len ( arr ) ; NEW
tokenizer.decode(t,: def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT printRotation ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 3 , 4 , 4 , 5 , 4 ] NEW_LINE n
tokenizer.decode(t,: def findCount ( A , B ) : NEW_LINE INDENT n = len ( A ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( A [ i ] == B [ i ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT A = " gcd " NEW_LINE B = " gcd " NEW_LINE print ( countCount ( A ) ) NEW_LINE
tokenizer.decode(t,: def longestSubsequence ( arr , n , x ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT elif ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT print ( cnt ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [
tokenizer.decode(t,: def countSubsets ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT ans += arr [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 1 , 1 , 1 , 1 , 1 ] NEW_LINE N = len ( arr ) NEW_LINE K = 2 NEW_LINE print ( countSubsets ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countPairs ( arr , N , K ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( arr [ i ] % K == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( countPairs ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( A , B , N , X , Y ) : NEW_LINE INDENT if ( X < Y ) : NEW_LINE INDENT return True NEW_LINE DEDENT if ( X < Y ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( X < Y ) : NEW_LINE INDENT return False NEW_LINE DEDENT return False NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 3 , 3 , 5 , 5 ] NEW_LINE B = [ 3 , 5 , 5 ] NEW_LINE N = len ( A ) NEW_LINE if ( isPossible ( A , N , X ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DED
tokenizer.decode(t,: def minOperations ( arr , N ) : NEW_LINE INDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefix_sum += arr [ i ] NEW_LINE prefix_sum += arr [ i ] NEW_LINE DEDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefix_sum += arr [ i ] NEW_LINE prefix_sum += prefix_sum NEW_LINE prefix_sum += prefix_sum NEW_LINE prefix_sum += prefix_sum - prefix_sum NEW_LINE prefix_sum += prefix_sum NEW_LINE DEDENT return prefix_sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2
tokenizer.decode(t,: def minOperations ( A , N ) : NEW_LINE INDENT A = [ ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT print ( A [ i ] , end = " ▁ " ) NEW_LINE DEDENT print ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1
tokenizer.decode(t,: import sys NEW_LINE def minOperations ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1
tokenizer.decode(t,: import sys NEW_LINE def check ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW
tokenizer.decode(t,: def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = [ 1 , 0 , 0 , 0 , 0 ] NEW_LINE n = len ( a ) NEW_LINE k = 2 NEW_LINE print ( maxSum ( a , n , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def palindrome ( s ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == ' a ' ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == ' a ' ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT return cnt NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE print ( s ) NEW_LINE DEDENT
tokenizer.decode(t,: import math as mt NEW_LINE def findString ( str , n ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT cnt += ord ( str [ i ] ) - ord ( ' a ' ) NEW_LINE DEDENT return cnt NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT str = " geeksforgeeks " NEW_LINE n = len ( str ) NEW_LINE print ( findString ( str ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countOccurrence ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE count = 0 NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if s [ i ] == s [ i ] : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT s = " geeksforgeeks " NEW_LINE print ( countWords ( s ) ) NEW_LINE
tokenizer.decode(t,: def circlearea ( r ) : NEW_LINE INDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 ; NEW_LINE DEDENT return - 1 ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT r = 5 ; NEW_LINE print ( circlearea ( r ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def minDifference ( arr , N ) : NEW_LINE INDENT arr . sort ( ) NEW_LINE arr . sort ( reverse = False ) NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] != arr [ i - 1 ] ) : NEW_LINE INDENT arr [ i ] = arr [ i + 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT arr [ i ] = arr [ i + 1 ] NEW_LINE DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( arr [ i ] == arr [ j ] ) : NEW_LINE INDENT arr [ i ] = arr [ j ] NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT print
tokenizer.decode(t,: import math NEW_LINE def productProduct ( arr , n ) : NEW_LINE INDENT product = 1 NEW_LINE for i in range ( n ) : NEW_LINE INDENT product *= arr [ i ] NEW_LINE DEDENT return product NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 5 ] NEW_LINE n = len ( arr ) NEW_LINE print ( productProduct ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y , y ) : NEW_LINE INDENT if ( x < y ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 2 NEW_LINE y = 2 NEW_LINE y = 3 NEW_LINE isPossible ( x , y ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y , y ) : NEW_LINE INDENT if ( y < y ) : NEW_LINE INDENT return False NEW_LINE DEDENT return False NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 10 NEW_LINE y = 9 NEW_LINE y = 9 NEW_LINE if ( isPossible ( x , y ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSum ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] >= K ) : NEW_LINE INDENT ans += arr [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT ans = max ( ans , arr [ i ] ) NEW_LINE DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 , 3 , 4 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( maxSum ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isPrimeFactors ( n ) : NEW_LINE INDENT count = 0 NEW_LINE while ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE n = n // 2 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT for i in range ( 2 , int ( math . sqrt ( n ) ) + 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT return count NEW_LINE DEDENT def countPrimeFactors ( n ) : NEW_LINE INDENT count = 0 NEW_LINE count = 0 NEW_LINE while ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE count += 1 NEW_LINE DEDENT if ( count == 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def check ( X , Y ) : NEW_LINE INDENT if ( X == Y ) : NEW_LINE INDENT print ( " X " ) NEW_LINE return NEW_LINE DEDENT print ( " X " ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT X = 2 NEW_LINE Y = 3 NEW_LINE Y = 3 NEW_LINE print ( X , Y ) NEW_LINE DEDENT
tokenizer.decode(t,: def printSum ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE findSum ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( arr1 , arr2 , n ) : NEW_LINE INDENT sum1 = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT for i in range ( 0 , n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT for i in range ( 0 , n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT return sum1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr1 = [ 1 , 2 , 3 ] NEW_LINE n = len ( arr1 ) NEW_LINE if ( isPossible ( arr1 , n2 ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE IND
tokenizer.decode(t,: def summum ( n ) : NEW_LINE INDENT return ( n * ( n * n + 1 ) * ( n + 1 ) ) NEW_LINE DEDENT n = 5 NEW_LINE print ( summum ( n ) ) NEW_LINE
tokenizer.decode(t,: def countPairs ( arr , n ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE countPairs ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def minOperations ( n , m ) : NEW_LINE INDENT if ( m == 0 ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m == 0 ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT else : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT n = 5 ; m = 5 ; NEW_LINE m = 4 ; NEW_LINE m = 4 ; NEW_LINE print ( minOperations ( n , m ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def reverse ( n ) : NEW_LINE INDENT rev = 0 ; NEW_LINE while ( n > 0 ) : NEW_LINE INDENT rev = rev * 10 ; NEW_LINE rev = rev * 10 ; NEW_LINE n = rev * 10 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 10 ; NEW_LINE print ( reverse ( n ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( str1 , str2 ) : NEW_LINE INDENT count = [ 0 ] * 26 NEW_LINE for i in range ( len ( str1 ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( len ( str1 ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( 0 , len ( str1 [ 0 ] ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( 26 ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE D
tokenizer.decode(t,: import math NEW_LINE def countTriangles ( n ) : NEW_LINE INDENT return math . sqrt ( n - 1 ) / 2 NEW_LINE DEDENT n = 3 NEW_LINE print ( countTriangles ( n ) ) NEW_LINE
tokenizer.decode(t,: def findSubstring ( s , k ) : NEW_LINE INDENT n = len ( s ) NEW_LINE ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i , n ) : NEW_LINE INDENT if ( s [ j ] == s [ j ] ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT else : NEW_LINE INDENT ans += s [ j ] NEW_LINE DEDENT DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE print ( findSubstring ( s , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def check ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE arr [ i ] = arr [ i ] NEW_LINE DEDENT DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def sort ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT
tokenizer.decode(t,: def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += abs ( arr [ i ] - arr [ i ] ) NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 ] NEW_LINE n = len ( arr ) NEW_LINE print ( minDiff ( arr , n ) ) NEW_LINE DEDENT
usage: evaluator.py [-h] [--references REFERENCES] [--predictions PREDICTIONS]
evaluator.py: error: unrecognized arguments:  
run_NL_PL_new.sh: line 220: --references: command not found
usage: calc_code_bleu.py [-h] --refs REFS [REFS ...] --hyp HYP --lang
                         {java,javascript,c_sharp,php,go,python,cpp,c,ruby}
                         [--params PARAMS]
calc_code_bleu.py: error: the following arguments are required: --refs, --hyp, --lang
run_NL_PL_new.sh: line 226: --ref: command not found
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ START EVAL @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Source: desc Target: python
Data path: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/
Pre-trained model: microsoft/codebert-base
Model type: roberta
Experiment name: codebert_nl_pl_program
TEST_FILE_SRC: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt TEST_FILE_TGT: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
03/22/2023 18:36:47 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/codebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=16, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py', tokenizer_name='microsoft/codebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
03/22/2023 18:36:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/22/2023 18:36:54 - INFO - __main__ -   reload model from /home/ysnamgoong42/ws/XLCoST/code/../codebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin
03/22/2023 18:36:56 - INFO - __main__ -   Test file: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
  0%|          | 0/56 [00:00<?, ?it/s]  2%|▏         | 1/56 [00:19<18:13, 19.89s/it]  4%|▎         | 2/56 [00:37<16:54, 18.79s/it]  5%|▌         | 3/56 [00:55<16:13, 18.38s/it]  7%|▋         | 4/56 [01:14<15:59, 18.44s/it]  9%|▉         | 5/56 [01:31<15:25, 18.15s/it] 11%|█         | 6/56 [01:47<14:17, 17.16s/it] 12%|█▎        | 7/56 [02:06<14:42, 18.02s/it] 14%|█▍        | 8/56 [02:27<15:09, 18.94s/it] 16%|█▌        | 9/56 [02:50<15:39, 20.00s/it] 18%|█▊        | 10/56 [03:08<14:49, 19.35s/it] 20%|█▉        | 11/56 [03:25<14:01, 18.70s/it] 21%|██▏       | 12/56 [03:43<13:34, 18.50s/it] 23%|██▎       | 13/56 [04:01<13:10, 18.39s/it] 25%|██▌       | 14/56 [04:21<13:11, 18.85s/it] 27%|██▋       | 15/56 [04:43<13:35, 19.88s/it] 29%|██▊       | 16/56 [05:03<13:09, 19.73s/it] 30%|███       | 17/56 [05:21<12:38, 19.44s/it] 32%|███▏      | 18/56 [05:38<11:47, 18.61s/it] 34%|███▍      | 19/56 [05:58<11:40, 18.93s/it] 36%|███▌      | 20/56 [06:19<11:46, 19.62s/it] 38%|███▊      | 21/56 [06:40<11:41, 20.06s/it] 39%|███▉      | 22/56 [06:55<10:29, 18.51s/it] 41%|████      | 23/56 [07:16<10:39, 19.37s/it] 43%|████▎     | 24/56 [07:37<10:32, 19.77s/it] 45%|████▍     | 25/56 [07:56<10:04, 19.50s/it] 46%|████▋     | 26/56 [08:17<10:00, 20.01s/it] 48%|████▊     | 27/56 [08:37<09:42, 20.10s/it] 50%|█████     | 28/56 [08:56<09:13, 19.78s/it] 52%|█████▏    | 29/56 [09:15<08:48, 19.56s/it] 54%|█████▎    | 30/56 [09:34<08:20, 19.23s/it] 55%|█████▌    | 31/56 [09:55<08:16, 19.85s/it] 57%|█████▋    | 32/56 [10:16<08:03, 20.14s/it] 59%|█████▉    | 33/56 [10:35<07:34, 19.77s/it] 61%|██████    | 34/56 [10:54<07:09, 19.52s/it] 62%|██████▎   | 35/56 [11:14<06:55, 19.77s/it] 64%|██████▍   | 36/56 [11:34<06:32, 19.62s/it] 66%|██████▌   | 37/56 [11:50<05:57, 18.82s/it] 68%|██████▊   | 38/56 [12:05<05:15, 17.54s/it] 70%|██████▉   | 39/56 [12:24<05:07, 18.07s/it] 71%|███████▏  | 40/56 [12:43<04:54, 18.39s/it] 73%|███████▎  | 41/56 [12:58<04:17, 17.18s/it] 75%|███████▌  | 42/56 [13:13<03:53, 16.69s/it] 77%|███████▋  | 43/56 [13:31<03:39, 16.85s/it] 79%|███████▊  | 44/56 [13:49<03:26, 17.22s/it] 80%|████████  | 45/56 [14:04<03:03, 16.70s/it] 82%|████████▏ | 46/56 [14:21<02:46, 16.69s/it] 84%|████████▍ | 47/56 [14:37<02:28, 16.47s/it] 86%|████████▌ | 48/56 [14:54<02:12, 16.61s/it] 88%|████████▊ | 49/56 [15:08<01:51, 15.96s/it] 89%|████████▉ | 50/56 [15:26<01:38, 16.38s/it] 91%|█████████ | 51/56 [15:41<01:20, 16.14s/it] 93%|█████████▎| 52/56 [15:59<01:06, 16.53s/it] 95%|█████████▍| 53/56 [16:17<00:51, 17.25s/it] 96%|█████████▋| 54/56 [16:37<00:36, 18.03s/it] 98%|█████████▊| 55/56 [16:58<00:18, 18.69s/it]100%|██████████| 56/56 [17:07<00:00, 15.85s/it]100%|██████████| 56/56 [17:07<00:00, 18.34s/it]
03/22/2023 18:54:04 - INFO - __main__ -     bleu-4 = 21.55 
03/22/2023 18:54:04 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:54:04 - INFO - __main__ -     ********************
tokenizer.decode(t,: def minSum ( arr , N ) : NEW_LINE INDENT mp = { } NEW_LINE for i in range ( N ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if arr [ i ] in mp : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT else : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( minSum ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def getBinary ( n , k ) : NEW_LINE INDENT ans = 0 NEW_LINE while ( n > 0 ) : NEW_LINE INDENT n = n % 10 NEW_LINE n = n // 10 NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( 1 , n ) : NEW_LINE INDENT ans += ( n & ( 1 << i ) ) NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n , k ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans = ans [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT def getBinary ( n ) : NEW_LINE INDENT return ans NEW_LINE DED
tokenizer.decode(t,: from bisect import bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_right = bisect_right NEW_LINE bisect_right = bisect_left ( bisect_right , bisect_right , bisect_right ) NEW_LINE bisect_right = bisect_left ( bisect_right , bisect_right , bisect_right ) NEW_LINE for i in range ( len ( bisect_right ) ) : NEW_LINE INDENT for j in range ( len ( v ) ) : NEW_LINE INDENT if ( v [ i ] [ j ] == '1' ) : NEW_LINE INDENT v . append ( v [ i ] ) NEW_LINE DEDENT DEDENT DEDENT v . sort ( reverse ( ) ) NEW_LINE for i in range ( len ( v ) ) : NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def isValid ( x , y ) : NEW_LINE INDENT if ( x < y ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT elif ( x % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE D
tokenizer.decode(t,: from math import sqrt NEW_LINE def countRectangles ( X , Y ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( 1 , Y + 1 ) : NEW_LINE INDENT ans += ( Y * Y + Y ) NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT X = 5 NEW_LINE Y = 5 NEW_LINE print ( countRectangles ( X , Y ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def check ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT if ( s [ i ] != s [ i - 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = "11" NEW_LINE if ( check ( s ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: import math NEW_LINE def findKthBit ( n ) : NEW_LINE INDENT if ( n == 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT return - 1 NEW_LINE DEDENT n = 10 NEW_LINE print ( findKthBit ( n ) ) NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT printArr ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT arr = [ 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE printArr ( arr , n ) NEW_LINE
tokenizer.decode(t,: def findMissing ( arr , n ) : NEW_LINE INDENT for i in range ( 0 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i - 1 ] ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT DEDENT return - 1 NEW_LINE DEDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( findMissing ( arr , n ) ) NEW_LINE
tokenizer.decode(t,: MAX_CHAR = 26 NEW_LINE def lcs ( str1 , str2 ) : NEW_LINE INDENT lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE lcs = [ [ 0 for i in range ( MAX_CHAR ) ] for j in range ( MAX_CHAR ) ] NEW_LINE
tokenizer.decode(t,: def fact ( n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT print ( "1" ) NEW_LINE return NEW_LINE DEDENT else : NEW_LINE INDENT print ( "1" ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE print ( round ( n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: mod = 1000000007 NEW_LINE def power ( x , y ) : NEW_LINE INDENT if ( x == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT x = x * x NEW_LINE while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT x = y >> 1 NEW_LINE DEDENT y = y >> 1 NEW_LINE x = y >> 1 NEW_LINE DEDENT return x NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT x = y >> 1 NEW_LINE y = y >> 1 NEW_LINE DEDENT return x NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT if (
tokenizer.decode(t,: def countTriplets ( arr , N ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( N ) : NEW_LINE INDENT if ( arr [ i ] & 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 0 , 0 , 0 ] NEW_LINE N = len ( arr ) NEW_LINE countTriplets ( arr , N ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def areaArea ( area ) : NEW_LINE INDENT area = area * area NEW_LINE return area NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT area = 5 NEW_LINE print ( areaSquareArea ( area ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minimumSwaps ( A , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( A [ i ] == K ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT else : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT DEDENT print ( ans ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ] NEW_LINE N = len ( A ) NEW_LINE minimumSwaps ( A , N ) NEW_LINE D
tokenizer.decode(t,: def lds ( arr , n ) : NEW_LINE INDENT lis = [ ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT lis [ i ] = arr [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT for j in range ( n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT return lis
tokenizer.decode(t,: def sumOfAP ( a , n ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT sum += a * a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT a = 2 NEW_LINE b = 2 NEW_LINE print ( sumOfAP ( a , n ) ) NEW_LINE
tokenizer.decode(t,: def sortArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE sortArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSquare ( a , b ) : NEW_LINE INDENT return a * b NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = 4 NEW_LINE print ( maxSquare ( a , b ) ) NEW_LINE DEDENT
tokenizer.decode(t,: MAX = 100 NEW_LINE def countWays ( mat , n , m ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( m ) : NEW_LINE INDENT for j in range ( m ) : NEW_LINE INDENT if ( mat [ i ] [ j ] == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT mat = [ [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 ] , [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ] , [ 1 , 1 , 1
tokenizer.decode(t,: dp = [ [ [ - 1 for i in range ( 100 ) ] for j in range ( 100 ) ] NEW_LINE def countPaths ( n , k ) : NEW_LINE INDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( countPaths ( n , k ) ) : NEW_LINE INDENT
tokenizer.decode(t,: def setBits ( a , b ) : NEW_LINE INDENT if ( a & b ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT a = b >> 1 NEW_LINE b = a >> 1 NEW_LINE while ( b ) : NEW_LINE INDENT a = b & b NEW_LINE b = b >> 1 NEW_LINE DEDENT return a NEW_LINE DEDENT a = 10 NEW_LINE b = 10 NEW_LINE print ( " Sum ▁ of ▁ of ▁ of ▁ of ▁ of ▁ is ▁ of ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ is ▁ " , b = " , " , " , " , " , " , " , " , " , " , "
tokenizer.decode(t,: def findXOR ( arr , n ) : NEW_LINE INDENT prefixXor = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT prefixXor ^= arr [ i ] ; NEW_LINE DEDENT return prefixXor ; NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] ; NEW_LINE n = len ( arr ) ; NEW
tokenizer.decode(t,: def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT printRotation ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 3 , 4 , 4 , 5 , 4 ] NEW_LINE n
tokenizer.decode(t,: def findCount ( A , B ) : NEW_LINE INDENT n = len ( A ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( A [ i ] == B [ i ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT A = " gcd " NEW_LINE B = " gcd " NEW_LINE print ( countCount ( A ) ) NEW_LINE
tokenizer.decode(t,: def longestSubsequence ( arr , n , x ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT elif ( arr [ i ] == x ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT print ( cnt ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [
tokenizer.decode(t,: def countSubsets ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT ans += arr [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 1 , 1 , 1 , 1 , 1 ] NEW_LINE N = len ( arr ) NEW_LINE K = 2 NEW_LINE print ( countSubsets ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countPairs ( arr , N , K ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( arr [ i ] % K == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( countPairs ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( A , B , N , X , Y ) : NEW_LINE INDENT if ( X < Y ) : NEW_LINE INDENT return True NEW_LINE DEDENT if ( X < Y ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( X < Y ) : NEW_LINE INDENT return False NEW_LINE DEDENT return False NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 3 , 3 , 5 , 5 ] NEW_LINE B = [ 3 , 5 , 5 ] NEW_LINE N = len ( A ) NEW_LINE if ( isPossible ( A , N , X ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DED
tokenizer.decode(t,: def minOperations ( arr , N ) : NEW_LINE INDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefix_sum += arr [ i ] NEW_LINE prefix_sum += arr [ i ] NEW_LINE DEDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefix_sum += arr [ i ] NEW_LINE prefix_sum += prefix_sum NEW_LINE prefix_sum += prefix_sum NEW_LINE prefix_sum += prefix_sum - prefix_sum NEW_LINE prefix_sum += prefix_sum NEW_LINE DEDENT return prefix_sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2
tokenizer.decode(t,: def minOperations ( A , N ) : NEW_LINE INDENT A = [ ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT print ( A [ i ] , end = " ▁ " ) NEW_LINE DEDENT print ( ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1
tokenizer.decode(t,: import sys NEW_LINE def minOperations ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT elif ( s [ i ] == '1' ) : NEW_LINE INDENT ans += 1
tokenizer.decode(t,: import sys NEW_LINE def check ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW
tokenizer.decode(t,: def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = [ 1 , 0 , 0 , 0 , 0 ] NEW_LINE n = len ( a ) NEW_LINE k = 2 NEW_LINE print ( maxSum ( a , n , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def palindrome ( s ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == ' a ' ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT else : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == ' a ' ) : NEW_LINE INDENT cnt += 1 NEW_LINE DEDENT DEDENT return cnt NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE print ( s ) NEW_LINE DEDENT
tokenizer.decode(t,: import math as mt NEW_LINE def findString ( str , n ) : NEW_LINE INDENT cnt = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT cnt += ord ( str [ i ] ) - ord ( ' a ' ) NEW_LINE DEDENT return cnt NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT str = " geeksforgeeks " NEW_LINE n = len ( str ) NEW_LINE print ( findString ( str ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countOccurrence ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE count = 0 NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if s [ i ] == s [ i ] : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT s = " geeksforgeeks " NEW_LINE print ( countWords ( s ) ) NEW_LINE
tokenizer.decode(t,: def circlearea ( r ) : NEW_LINE INDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 ; NEW_LINE DEDENT return - 1 ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT r = 5 ; NEW_LINE print ( circlearea ( r ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def minDifference ( arr , N ) : NEW_LINE INDENT arr . sort ( ) NEW_LINE arr . sort ( reverse = False ) NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] != arr [ i - 1 ] ) : NEW_LINE INDENT arr [ i ] = arr [ i + 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT arr [ i ] = arr [ i + 1 ] NEW_LINE DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( arr [ i ] == arr [ j ] ) : NEW_LINE INDENT arr [ i ] = arr [ j ] NEW_LINE break NEW_LINE DEDENT DEDENT DEDENT for i in range ( N ) : NEW_LINE INDENT print
tokenizer.decode(t,: import math NEW_LINE def productProduct ( arr , n ) : NEW_LINE INDENT product = 1 NEW_LINE for i in range ( n ) : NEW_LINE INDENT product *= arr [ i ] NEW_LINE DEDENT return product NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 5 ] NEW_LINE n = len ( arr ) NEW_LINE print ( productProduct ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y , y ) : NEW_LINE INDENT if ( x < y ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 2 NEW_LINE y = 2 NEW_LINE y = 3 NEW_LINE isPossible ( x , y ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y , y ) : NEW_LINE INDENT if ( y < y ) : NEW_LINE INDENT return False NEW_LINE DEDENT return False NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 10 NEW_LINE y = 9 NEW_LINE y = 9 NEW_LINE if ( isPossible ( x , y ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSum ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT if ( arr [ i ] >= K ) : NEW_LINE INDENT ans += arr [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT ans = max ( ans , arr [ i ] ) NEW_LINE DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 , 3 , 4 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( maxSum ( arr , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isPrimeFactors ( n ) : NEW_LINE INDENT count = 0 NEW_LINE while ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE n = n // 2 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT for i in range ( 2 , int ( math . sqrt ( n ) ) + 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT return count NEW_LINE DEDENT def countPrimeFactors ( n ) : NEW_LINE INDENT count = 0 NEW_LINE count = 0 NEW_LINE while ( n % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE count += 1 NEW_LINE DEDENT if ( count == 1 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def check ( X , Y ) : NEW_LINE INDENT if ( X == Y ) : NEW_LINE INDENT print ( " X " ) NEW_LINE return NEW_LINE DEDENT print ( " X " ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT X = 2 NEW_LINE Y = 3 NEW_LINE Y = 3 NEW_LINE print ( X , Y ) NEW_LINE DEDENT
tokenizer.decode(t,: def printSum ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE findSum ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( arr1 , arr2 , n ) : NEW_LINE INDENT sum1 = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT for i in range ( 0 , n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT for i in range ( 0 , n ) : NEW_LINE INDENT sum1 += arr2 [ i ] NEW_LINE DEDENT return sum1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr1 = [ 1 , 2 , 3 ] NEW_LINE n = len ( arr1 ) NEW_LINE if ( isPossible ( arr1 , n2 ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE IND
tokenizer.decode(t,: def summum ( n ) : NEW_LINE INDENT return ( n * ( n * n + 1 ) * ( n + 1 ) ) NEW_LINE DEDENT n = 5 NEW_LINE print ( summum ( n ) ) NEW_LINE
tokenizer.decode(t,: def countPairs ( arr , n ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE countPairs ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def minOperations ( n , m ) : NEW_LINE INDENT if ( m == 0 ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m == 0 ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT if ( m % m ) : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT else : NEW_LINE INDENT return 0 ; NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT n = 5 ; m = 5 ; NEW_LINE m = 4 ; NEW_LINE m = 4 ; NEW_LINE print ( minOperations ( n , m ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def reverse ( n ) : NEW_LINE INDENT rev = 0 ; NEW_LINE while ( n > 0 ) : NEW_LINE INDENT rev = rev * 10 ; NEW_LINE rev = rev * 10 ; NEW_LINE n = rev * 10 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 10 ; NEW_LINE print ( reverse ( n ) ) ; NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( str1 , str2 ) : NEW_LINE INDENT count = [ 0 ] * 26 NEW_LINE for i in range ( len ( str1 ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( len ( str1 ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( 0 , len ( str1 [ 0 ] ) ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE DEDENT for i in range ( 26 ) : NEW_LINE INDENT count [ ord ( str1 [ i ] ) - ord ( ' a ' ) ] += 1 NEW_LINE D
tokenizer.decode(t,: import math NEW_LINE def countTriangles ( n ) : NEW_LINE INDENT return math . sqrt ( n - 1 ) / 2 NEW_LINE DEDENT n = 3 NEW_LINE print ( countTriangles ( n ) ) NEW_LINE
tokenizer.decode(t,: def findSubstring ( s , k ) : NEW_LINE INDENT n = len ( s ) NEW_LINE ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i , n ) : NEW_LINE INDENT if ( s [ j ] == s [ j ] ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT else : NEW_LINE INDENT ans += s [ j ] NEW_LINE DEDENT DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE print ( findSubstring ( s , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def check ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE arr [ i ] = arr [ i ] NEW_LINE DEDENT DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT arr [ i ] = arr [ i ] NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def sort ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if arr [ i ] > arr [ i ] : NEW_LINE INDENT
tokenizer.decode(t,: def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += abs ( arr [ i ] - arr [ i ] ) NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 ] NEW_LINE n = len ( arr ) NEW_LINE print ( minDiff ( arr , n ) ) NEW_LINE DEDENT
usage: evaluator.py [-h] [--references REFERENCES] [--predictions PREDICTIONS]
evaluator.py: error: unrecognized arguments:  
run_NL_PL_new.sh: line 220: --references: command not found
usage: calc_code_bleu.py [-h] --refs REFS [REFS ...] --hyp HYP --lang
                         {java,javascript,c_sharp,php,go,python,cpp,c,ruby}
                         [--params PARAMS]
calc_code_bleu.py: error: the following arguments are required: --refs, --hyp, --lang
run_NL_PL_new.sh: line 226: --ref: command not found
