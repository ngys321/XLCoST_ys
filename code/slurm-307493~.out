@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
probing_case 도입


@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ RUNNING SCRIPT: job_n_NoAug_py_graphcodebert_syn.sh

Wed Mar 22 17:05:28 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |
| 30%   30C    P8    29W / 350W |      1MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Jun__8_16:49:14_PDT_2022
Cuda compilation tools, release 11.7, V11.7.99
Build cuda_11.7.r11.7/compiler.31442593_0
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ START TRAIN @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Source: desc Target: python
Data path: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/
Pre-trained model: microsoft/graphcodebert-base
Model type: roberta
Experiment name: graphcodebert_nl_pl_program
TEST_FILE_SRC: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt TEST_FILE_TGT: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
/home/ysnamgoong42/ws/XLCoST/code
03/22/2023 17:05:32 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/val-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/val-Python-desc-tok.py', do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_batch_size=16, eval_steps=2500, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=10.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename=None, tokenizer_name='microsoft/graphcodebert-base', train_batch_size=16, train_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/train-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/train-Python-desc-tok.py', train_steps=5000, warmup_steps=0, weight_decay=0.0)
03/22/2023 17:05:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/22/2023 17:05:44 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:44 - INFO - __main__ -   idx: 0
03/22/2023 17:05:44 - INFO - __main__ -   source_tokens: ['<s>', 'Maximum', '_Pre', 'fix', '_Sum', '_possible', '_by', '_merging', '_two', '_given', '_arrays', '_|', '_Python', '3', '_implementation', '_of', '_the', '_above', '_approach', '_;', '_Stores', '_the', '_maximum', '_prefix', '_sum', '_of', '_the', '_array', '_A', '_[', '_]', '_;', '_Tra', 'verse', '_the', '_array', '_A', '_[', '_]', '_;', '_Stores', '_the', '_maximum', '_prefix', '_sum', '_of', '_the', '_array', '_B', '_[', '_]', '_;', '_Tra', 'verse', '_the', '_array', '_B', '_[', '_]', '_;', '_Driver', '_code', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   source_ids: 0 48089 5048 23032 9430 678 30 29002 80 576 42156 1721 31886 246 5574 9 5 1065 1548 25606 19225 5 4532 46622 6797 9 5 8932 83 646 27779 25606 8221 15189 5 8932 83 646 27779 25606 19225 5 4532 46622 6797 9 5 8932 163 646 27779 25606 8221 15189 5 8932 163 646 27779 25606 16870 3260 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   target_tokens: ['<s>', 'def', '_max', 'Pres', 'um', '_(', '_a', '_,', '_b', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_X', '_=', '_max', '_(', '_a', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_a', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_a', '_[', '_i', '_]', '_+=', '_a', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_X', '_=', '_max', '_(', '_X', '_,', '_a', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_Y', '_=', '_max', '_(', '_b', '_[', '_0', '_]', '_,', '_0', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_1', '_,', '_len', '_(', '_b', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_b', '_[', '_i', '_]', '_+=', '_b', '_[', '_i', '_-', '_1', '_]', '_NEW', '_', 'LINE', '_Y', '_=', '_max', '_(', '_Y', '_,', '_b', '_[', '_i', '_]', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_return', '_X', '_+', '_Y', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_A', '_=', '_[', '_2', '_,', '_-', '_1', '_,', '_4', '_,', '_-', '_5', '_]', '_NEW', '_', 'LINE', '_B', '_=', '_[', '_4', '_,', '_-', '_3', '_,', '_12', '_,', '_4', '_,', '_-', '_3', '_]', '_NEW', '_', 'LINE', '_print', '_(', '_max', 'Pres', 'um', '_(', '_A', '_,', '_B', '_)', '_)', '_NEW', '_', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   target_ids: 0 9232 19220 28917 783 36 10 2156 741 4839 4832 5178 1215 28302 12569 5382 1577 5457 19220 36 10 646 321 27779 2156 321 4839 5178 1215 28302 13 939 11 1186 36 112 2156 25528 36 10 4839 4839 4832 5178 1215 28302 12569 5382 10 646 939 27779 49371 10 646 939 111 112 27779 5178 1215 28302 1577 5457 19220 36 1577 2156 10 646 939 27779 4839 5178 1215 28302 211 1691 5382 854 5457 19220 36 741 646 321 27779 2156 321 4839 5178 1215 28302 13 939 11 1186 36 112 2156 25528 36 741 4839 4839 4832 5178 1215 28302 12569 5382 741 646 939 27779 49371 741 646 939 111 112 27779 5178 1215 28302 854 5457 19220 36 854 2156 741 646 939 27779 4839 5178 1215 28302 211 1691 5382 671 1577 2055 854 5178 1215 28302 211 1691 5382 83 5457 646 132 2156 111 112 2156 204 2156 111 195 27779 5178 1215 28302 163 5457 646 204 2156 111 155 2156 316 2156 204 2156 111 155 27779 5178 1215 28302 5780 36 19220 28917 783 36 83 2156 163 4839 4839 5178 1215 2
03/22/2023 17:05:44 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:44 - INFO - __main__ -   idx: 1
03/22/2023 17:05:44 - INFO - __main__ -   source_tokens: ['<s>', 'Check', '_if', '_a', '_number', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_positive', '_perfect', '_cubes', '_|', '_Python', '3', '_program', '_for', '_the', '_above', '_approach', '_;', '_Function', '_to', '_check', '_if', '_N', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_perfect', '_cubes', '_or', '_not', '_;', '_If', '_it', '_is', '_same', '_return', '_true', '_;', '_;', '_If', '_the', '_cur', 'r', '_smaller', '_than', '_n', '_increment', '_the', '_lo', '_;', '_If', '_the', '_cur', 'r', '_is', '_greater', '_than', '_cur', 'r', '_decre', 'ment', '_the', '_hi', '_;', '_Driver', '_Code', '_;', '_Function', '_call', '_to', '_check', '_if', '_N', '_can', '_be', '_represented', '_as', '_sum', '_of', '_two', '_perfect', '_cubes', '_or', '_not', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   source_ids: 0 26615 114 10 346 64 28 4625 25 6797 9 80 1313 1969 35788 1721 31886 246 586 13 5 1065 1548 25606 42419 7 1649 114 234 64 28 4625 25 6797 9 80 1969 35788 50 45 25606 318 24 16 276 671 1528 25606 25606 318 5 5350 338 2735 87 295 30401 5 4600 25606 318 5 5350 338 16 2388 87 5350 338 33186 1757 5 20280 25606 16870 8302 25606 42419 486 7 1649 114 234 64 28 4625 25 6797 9 80 1969 35788 50 45 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   target_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_lo', '_=', '_1', '_NEW', '_', 'LINE', '_hi', '_=', '_round', '_(', '_math', '_.', '_pow', '_(', '_n', '_,', '_1', '_/', '_3', '_)', '_)', '_NEW', '_', 'LINE', '_while', '_(', '_lo', '_<=', '_hi', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_cur', 'r', '_=', '_(', '_lo', '_*', '_lo', '_*', '_lo', '_+', '_hi', '_*', '_hi', '_*', '_hi', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_cur', 'r', '_==', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_True', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_cur', 'r', '_<', '_n', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_lo', '_+=', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_else', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_hi', '_-=', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_return', '_False', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_N', '_=', '_28', '_NEW', '_', 'LINE', '_if', '_(', '_sum', 'Of', 'Two', 'C', 'ubes', '_(', '_N', '_)', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_print', '_(', '_"', '_True', '_"', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_else', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_print', '_(', '_"', '_False', '_"', '_)', '_NEW', '_', 'LINE', '_D', 'ED', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   target_ids: 0 41975 10638 5178 1215 28302 3816 6797 10643 9058 347 39749 36 295 4839 4832 5178 1215 28302 12569 5382 4600 5457 112 5178 1215 28302 20280 5457 1062 36 10638 479 30964 36 295 2156 112 1589 155 4839 4839 5178 1215 28302 150 36 4600 49230 20280 4839 4832 5178 1215 28302 12569 5382 5350 338 5457 36 4600 1009 4600 1009 4600 2055 20280 1009 20280 1009 20280 4839 5178 1215 28302 114 36 5350 338 45994 295 4839 4832 5178 1215 28302 12569 5382 671 7447 5178 1215 28302 211 1691 5382 114 36 5350 338 28696 295 4839 4832 5178 1215 28302 12569 5382 4600 49371 112 5178 1215 28302 211 1691 5382 1493 4832 5178 1215 28302 12569 5382 20280 49826 112 5178 1215 28302 211 1691 5382 211 1691 5382 671 35297 5178 1215 28302 211 1691 5382 234 5457 971 5178 1215 28302 114 36 6797 10643 9058 347 39749 36 234 4839 4839 4832 5178 1215 28302 12569 5382 5780 36 22 7447 22 4839 5178 1215 28302 211 1691 5382 1493 4832 5178 1215 28302 12569 5382 5780 36 22 35297 22 4839 5178 1215 28302 211 1691 2
03/22/2023 17:05:44 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:44 - INFO - __main__ -   idx: 2
03/22/2023 17:05:44 - INFO - __main__ -   source_tokens: ['<s>', 'Gener', 'ate', '_an', '_N', '_|', '_Python', '3', '_program', '_for', '_the', '_above', '_approach', '_;', '_Function', '_to', '_generate', '_all', '_prime', '_numbers', '_upt', 'o', '_10', '_^', '_6', '_;', '_Initial', 'ize', '_s', 'ieve', '_[', '_]', '_as', '_1', '_;', '_Iter', 'ate', '_over', '_the', '_range', '_[', '_2', '_,', '_N', '_]', '_;', '_If', '_current', '_element', '_is', '_non', '_-', '_prime', '_;', '_Make', '_all', '_multi', 'ples', '_of', '_i', '_as', '_0', '_;', '_Function', '_to', '_construct', '_an', '_array', '_A', '_[', '_]', '_satisfying', '_the', '_given', '_conditions', '_;', '_Stores', '_the', '_resultant', '_array', '_;', '_Stores', '_all', '_prime', '_numbers', '_;', '_S', 'ieve', '_of', '_Er', 'ast', 'ost', 'hen', 'es', '_;', '_App', 'end', '_the', '_integer', '_i', '_if', '_it', '_is', '_a', '_prime', '_;', '_Ind', 'icates', '_current', '_position', '_in', '_list', '_of', '_prime', '_numbers', '_;', '_Tra', 'verse', '_the', '_array', '_arr', '_[', '_]', '_;', '_If', '_already', '_filled', '_with', '_another', '_prime', '_number', '_;', '_If', '_A', '_[', '_i', '_]', '_is', '_not', '_filled', '_but', '_A', '_[', '_ind', '_]', '_is', '_filled', '_;', '_Store', '_A', '_[', '_i', '_]', '_=', '_A', '_[', '_ind', '_]', '_;', '_If', '_none', '_of', '_them', '_were', '_filled', '_;', '_To', '_make', '_sure', '_A', '_[', '_i', '_]', '_does', '_not', '_affect', '_other', '_values', '_,', '_store', '_next', '_prime', '_number', '_;', '_Print', '_the', '_resultant', '_array', '_;', '_Driver', '_Code', '_;', '_Function', '_Call', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   source_ids: 0 40025 877 41 234 1721 31886 246 586 13 5 1065 1548 25606 42419 7 5368 70 2654 1530 18256 139 158 37249 231 25606 24685 2072 579 16637 646 27779 25 112 25606 47476 877 81 5 1186 646 132 2156 234 27779 25606 318 595 7510 16 786 111 2654 25606 5293 70 3228 12349 9 939 25 321 25606 42419 7 12558 41 8932 83 646 27779 17758 5 576 1274 25606 19225 5 41474 8932 25606 19225 70 2654 1530 25606 208 16637 9 4594 1988 2603 2457 293 25606 3166 1397 5 48335 939 114 24 16 10 2654 25606 4619 23020 595 737 11 889 9 2654 1530 25606 8221 15189 5 8932 25743 646 27779 25606 318 416 3820 19 277 2654 346 25606 318 83 646 939 27779 16 45 3820 53 83 646 9473 27779 16 3820 25606 7248 83 646 939 27779 5457 83 646 9473 27779 25606 318 4146 9 106 58 3820 25606 598 146 686 83 646 939 27779 473 45 3327 97 3266 2156 1400 220 2654 346 25606 6883 5 41474 8932 25606 16870 8302 25606 42419 3310 2 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   target_tokens: ['<s>', 's', 'ieve', '_=', '_[', '_1', '_]', '_*', '_(', '_100', '0000', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_def', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_N', '_=', '_100', '0000', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_N', '_+', '_1', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_if', '_i', '_*', '_i', '_>', '_N', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_break', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_s', 'ieve', '_[', '_i', '_]', '_==', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_continue', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_for', '_j', '_in', '_range', '_(', '_i', '_*', '_i', '_,', '_N', '_+', '_1', '_,', '_i', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_s', 'ieve', '_[', '_j', '_]', '_=', '_0', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_D', 'ED', 'ENT', '_def', '_get', 'Array', '_(', '_arr', '_,', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_global', '_s', 'ieve', '_NEW', '_', 'LINE', '_A', '_=', '_[', '_0', '_]', '_*', '_N', '_NEW', '_', 'LINE', '_v', '_=', '_[', '_]', '_NEW', '_', 'LINE', '_s', 'ieve', 'Of', 'Pr', 'imes', '_(', '_)', '_NEW', '_', 'LINE', '_for', '_i', '_in', '_range', '_(', '_2', '_,', '_int', '_(', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   target_ids: 0 29 16637 5457 646 112 27779 1009 36 727 14200 2055 112 4839 5178 1215 28302 3816 579 16637 10643 21077 9452 36 4839 4832 5178 1215 28302 12569 5382 720 579 16637 5178 1215 28302 234 5457 727 14200 5178 1215 28302 13 939 11 1186 36 132 2156 234 2055 112 4839 4832 5178 1215 28302 12569 5382 114 939 1009 939 8061 234 4832 5178 1215 28302 12569 5382 1108 5178 1215 28302 211 1691 5382 114 36 579 16637 646 939 27779 45994 321 4839 4832 5178 1215 28302 12569 5382 535 5178 1215 28302 211 1691 5382 13 1236 11 1186 36 939 1009 939 2156 234 2055 112 2156 939 4839 4832 5178 1215 28302 12569 5382 579 16637 646 1236 27779 5457 321 5178 1215 28302 211 1691 5382 211 1691 5382 211 1691 5382 3816 120 48222 36 25743 2156 234 4839 4832 5178 1215 28302 12569 5382 720 579 16637 5178 1215 28302 83 5457 646 321 27779 1009 234 5178 1215 28302 748 5457 646 27779 5178 1215 28302 579 16637 10643 21077 9452 36 4839 5178 1215 28302 13 939 11 1186 36 132 2156 6979 36 2
03/22/2023 17:05:44 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:44 - INFO - __main__ -   idx: 3
03/22/2023 17:05:44 - INFO - __main__ -   source_tokens: ['<s>', 'N', 'th', '_natural', '_number', '_after', '_removing', '_all', '_numbers', '_consisting', '_of', '_the', '_digit', '_9', '_|', '_Function', '_to', '_find', '_N', 'th', '_number', '_in', '_base', '_9', '_;', '_Stores', '_the', '_N', 'th', '_number', '_;', '_Iter', 'ate', '_while', '_N', '_is', '_greater', '_than', '_0', '_;', '_Update', '_result', '_;', '_Divide', '_N', '_by', '_9', '_;', '_Mult', 'ip', 'ly', '_p', '_by', '_10', '_;', '_Return', '_result', '_;', '_Driver', '_Code', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   source_ids: 0 487 212 1632 346 71 8201 70 1530 17402 9 5 16808 361 1721 42419 7 465 234 212 346 11 1542 361 25606 19225 5 234 212 346 25606 47476 877 150 234 16 2388 87 321 25606 14686 898 25606 39030 234 30 361 25606 14910 1588 352 181 30 158 25606 11968 898 25606 16870 8302 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   target_tokens: ['<s>', 'def', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_result', '_=', '_0', '_NEW', '_', 'LINE', '_p', '_=', '_1', '_NEW', '_', 'LINE', '_while', '_(', '_N', '_>', '_0', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_result', '_+=', '_(', '_p', '_*', '_(', '_N', '_%', '_9', '_)', '_)', '_NEW', '_', 'LINE', '_N', '_=', '_N', '_//', '_9', '_NEW', '_', 'LINE', '_p', '_=', '_p', '_*', '_10', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_return', '_result', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '___', 'name', '__', '_==', "_'", '__', '__', '_main', '__', '__', "_'", '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_N', '_=', '_9', '_NEW', '_', 'LINE', '_print', '_(', '_find', 'N', 'th', 'Number', '_(', '_N', '_)', '_)', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   target_ids: 0 9232 465 487 212 43623 36 234 4839 4832 5178 1215 28302 12569 5382 898 5457 321 5178 1215 28302 181 5457 112 5178 1215 28302 150 36 234 8061 321 4839 4832 5178 1215 28302 12569 5382 898 49371 36 181 1009 36 234 7606 361 4839 4839 5178 1215 28302 234 5457 234 21277 361 5178 1215 28302 181 5457 181 1009 158 5178 1215 28302 211 1691 5382 671 898 5178 1215 28302 211 1691 5382 114 27148 13650 30529 45994 128 18134 18134 1049 18134 18134 128 4832 5178 1215 28302 12569 5382 234 5457 361 5178 1215 28302 5780 36 465 487 212 43623 36 234 4839 4839 5178 1215 28302 211 1691 5382 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   *** Example ***
03/22/2023 17:05:44 - INFO - __main__ -   idx: 4
03/22/2023 17:05:44 - INFO - __main__ -   source_tokens: ['<s>', 'Check', '_if', '_an', '_integer', '_is', '_rotation', '_of', '_another', '_given', '_integer', '_|', '_Python', '3', '_implementation', '_of', '_the', '_approach', '_;', '_Function', '_to', '_check', '_if', '_the', '_integer', '_A', '_is', '_a', '_rotation', '_of', '_the', '_integer', '_B', '_;', '_Stores', '_the', '_count', '_of', '_digits', '_in', '_A', '_;', '_Stores', '_the', '_count', '_of', '_digits', '_in', '_B', '_;', '_If', '_dig', '1', '_not', '_equal', '_to', '_dig', '2', '_;', '_Stores', '_position', '_of', '_first', '_digit', '_;', '_Stores', '_the', '_first', '_digit', '_;', '_Rot', 'ate', '_the', '_digits', '_of', '_the', '_integer', '_;', '_If', '_A', '_is', '_equal', '_to', '_B', '_;', '_If', '_A', '_is', '_equal', '_to', '_the', '_initial', '_value', '_of', '_integer', '_A', '_;', '_Driver', '_code', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   source_ids: 0 26615 114 41 48335 16 10134 9 277 576 48335 1721 31886 246 5574 9 5 1548 25606 42419 7 1649 114 5 48335 83 16 10 10134 9 5 48335 163 25606 19225 5 3212 9 15769 11 83 25606 19225 5 3212 9 15769 11 163 25606 318 8512 134 45 3871 7 8512 176 25606 19225 737 9 78 16808 25606 19225 5 78 16808 25606 9104 877 5 15769 9 5 48335 25606 318 83 16 3871 7 163 25606 318 83 16 3871 7 5 2557 923 9 48335 83 25606 16870 3260 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/22/2023 17:05:44 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/22/2023 17:05:44 - INFO - __main__ -   target_tokens: ['<s>', 'import', '_math', '_NEW', '_', 'LINE', '_def', '_check', '_(', '_A', '_,', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_dig', '1', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_A', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_dig', '2', '_=', '_math', '_.', '_floor', '_(', '_math', '_.', '_log', '10', '_(', '_B', '_)', '_+', '_1', '_)', '_NEW', '_', 'LINE', '_if', '_(', '_dig', '1', '_!=', '_dig', '2', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_0', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_temp', '_=', '_A', '_NEW', '_', 'LINE', '_while', '_(', '_True', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_power', '_=', '_pow', '_(', '_10', '_,', '_dig', '1', '_-', '_1', '_)', '_NEW', '_', 'LINE', '_first', 'digit', '_=', '_A', '_//', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_-', '_first', 'digit', '_*', '_power', '_NEW', '_', 'LINE', '_A', '_=', '_A', '_*', '_10', '_+', '_first', 'digit', '_NEW', '_', 'LINE', '_if', '_(', '_A', '_==', '_B', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_1', '_NEW', '_', 'LINE', '_D', 'ED', 'ENT', '_if', '_(', '_A', '_==', '_temp', '_)', '_:', '_NEW', '_', 'LINE', '_IND', 'ENT', '_return', '_0', '_NEW', '_', 'LINE', '</s>']
03/22/2023 17:05:44 - INFO - __main__ -   target_ids: 0 41975 10638 5178 1215 28302 3816 1649 36 83 2156 163 4839 4832 5178 1215 28302 12569 5382 114 36 83 45994 163 4839 4832 5178 1215 28302 12569 5382 671 112 5178 1215 28302 211 1691 5382 8512 134 5457 10638 479 1929 36 10638 479 7425 698 36 83 4839 2055 112 4839 5178 1215 28302 8512 176 5457 10638 479 1929 36 10638 479 7425 698 36 163 4839 2055 112 4839 5178 1215 28302 114 36 8512 134 49333 8512 176 4839 4832 5178 1215 28302 12569 5382 671 321 5178 1215 28302 211 1691 5382 32196 5457 83 5178 1215 28302 150 36 7447 4839 4832 5178 1215 28302 12569 5382 476 5457 30964 36 158 2156 8512 134 111 112 4839 5178 1215 28302 78 10289 5457 83 21277 476 5178 1215 28302 83 5457 83 111 78 10289 1009 476 5178 1215 28302 83 5457 83 1009 158 2055 78 10289 5178 1215 28302 114 36 83 45994 163 4839 4832 5178 1215 28302 12569 5382 671 112 5178 1215 28302 211 1691 5382 114 36 83 45994 32196 4839 4832 5178 1215 28302 12569 5382 671 321 5178 1215 28302 2
03/22/2023 17:05:44 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
/home/ysnamgoong42/miniconda3/envs/xlcost/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/22/2023 17:06:00 - INFO - __main__ -   ***** Running training *****
03/22/2023 17:06:00 - INFO - __main__ -     Num examples = 9263
03/22/2023 17:06:00 - INFO - __main__ -     Batch size = 16
03/22/2023 17:06:00 - INFO - __main__ -     Num epoch = 9
03/22/2023 17:06:28 - INFO - __main__ -     step 100 loss 3.2745
03/22/2023 17:06:55 - INFO - __main__ -     step 200 loss 2.7741
03/22/2023 17:07:23 - INFO - __main__ -     step 300 loss 2.5188
03/22/2023 17:07:50 - INFO - __main__ -     step 400 loss 2.3338
03/22/2023 17:08:17 - INFO - __main__ -     step 500 loss 2.1973
03/22/2023 17:08:45 - INFO - __main__ -     step 600 loss 2.0979
03/22/2023 17:09:12 - INFO - __main__ -     step 700 loss 2.014
03/22/2023 17:09:40 - INFO - __main__ -     step 800 loss 1.946
03/22/2023 17:10:07 - INFO - __main__ -     step 900 loss 1.8851
03/22/2023 17:10:34 - INFO - __main__ -     step 1000 loss 1.8309
03/22/2023 17:11:02 - INFO - __main__ -     step 1100 loss 1.7839
03/22/2023 17:11:18 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:11:18 - INFO - __main__ -     Num examples = 472
03/22/2023 17:11:18 - INFO - __main__ -     Batch size = 16
03/22/2023 17:11:21 - INFO - __main__ -     eval_ppl = 3.46231
03/22/2023 17:11:21 - INFO - __main__ -     global_step = 1157
03/22/2023 17:11:21 - INFO - __main__ -     train_loss = 1.7613
03/22/2023 17:11:21 - INFO - __main__ -     ********************
03/22/2023 17:11:27 - INFO - __main__ -     Best ppl:3.46231
03/22/2023 17:11:27 - INFO - __main__ -     ********************
03/22/2023 17:21:21 - INFO - __main__ -     bleu-4 = 15.99 
03/22/2023 17:21:21 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:21:21 - INFO - __main__ -     ********************
03/22/2023 17:21:21 - INFO - __main__ -     Best bleu:15.99
03/22/2023 17:21:21 - INFO - __main__ -     ********************
03/22/2023 17:21:36 - INFO - __main__ -     step 1200 loss 1.2981
03/22/2023 17:22:04 - INFO - __main__ -     step 1300 loss 1.277
03/22/2023 17:22:31 - INFO - __main__ -     step 1400 loss 1.2653
03/22/2023 17:22:58 - INFO - __main__ -     step 1500 loss 1.2431
03/22/2023 17:23:25 - INFO - __main__ -     step 1600 loss 1.2246
03/22/2023 17:23:52 - INFO - __main__ -     step 1700 loss 1.212
03/22/2023 17:24:19 - INFO - __main__ -     step 1800 loss 1.2023
03/22/2023 17:24:47 - INFO - __main__ -     step 1900 loss 1.1933
03/22/2023 17:25:14 - INFO - __main__ -     step 2000 loss 1.1819
03/22/2023 17:25:41 - INFO - __main__ -     step 2100 loss 1.1694
03/22/2023 17:26:08 - INFO - __main__ -     step 2200 loss 1.1567
03/22/2023 17:26:35 - INFO - __main__ -     step 2300 loss 1.1478
03/22/2023 17:26:38 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:26:38 - INFO - __main__ -     Num examples = 472
03/22/2023 17:26:38 - INFO - __main__ -     Batch size = 16
03/22/2023 17:26:41 - INFO - __main__ -     eval_ppl = 2.86943
03/22/2023 17:26:41 - INFO - __main__ -     global_step = 2314
03/22/2023 17:26:41 - INFO - __main__ -     train_loss = 1.1464
03/22/2023 17:26:41 - INFO - __main__ -     ********************
03/22/2023 17:26:47 - INFO - __main__ -     Best ppl:2.86943
03/22/2023 17:26:47 - INFO - __main__ -     ********************
03/22/2023 17:36:38 - INFO - __main__ -     bleu-4 = 17.51 
03/22/2023 17:36:38 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:36:38 - INFO - __main__ -     ********************
03/22/2023 17:36:38 - INFO - __main__ -     Best bleu:17.51
03/22/2023 17:36:38 - INFO - __main__ -     ********************
03/22/2023 17:37:08 - INFO - __main__ -     step 2400 loss 1.0362
03/22/2023 17:37:35 - INFO - __main__ -     step 2500 loss 1.0283
03/22/2023 17:38:02 - INFO - __main__ -     step 2600 loss 1.0209
03/22/2023 17:38:29 - INFO - __main__ -     step 2700 loss 1.0095
03/22/2023 17:38:56 - INFO - __main__ -     step 2800 loss 0.9972
03/22/2023 17:39:23 - INFO - __main__ -     step 2900 loss 0.9937
03/22/2023 17:39:50 - INFO - __main__ -     step 3000 loss 0.9895
03/22/2023 17:40:17 - INFO - __main__ -     step 3100 loss 0.9847
03/22/2023 17:40:44 - INFO - __main__ -     step 3200 loss 0.9784
03/22/2023 17:41:12 - INFO - __main__ -     step 3300 loss 0.9704
03/22/2023 17:41:39 - INFO - __main__ -     step 3400 loss 0.9632
03/22/2023 17:41:58 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:41:58 - INFO - __main__ -     Num examples = 472
03/22/2023 17:41:58 - INFO - __main__ -     Batch size = 16
03/22/2023 17:42:00 - INFO - __main__ -     eval_ppl = 2.6671
03/22/2023 17:42:00 - INFO - __main__ -     global_step = 3471
03/22/2023 17:42:00 - INFO - __main__ -     train_loss = 0.961
03/22/2023 17:42:00 - INFO - __main__ -     ********************
03/22/2023 17:42:05 - INFO - __main__ -     Best ppl:2.6671
03/22/2023 17:42:05 - INFO - __main__ -     ********************
03/22/2023 17:51:48 - INFO - __main__ -     bleu-4 = 18.6 
03/22/2023 17:51:48 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 17:51:48 - INFO - __main__ -     ********************
03/22/2023 17:51:48 - INFO - __main__ -     Best bleu:18.6
03/22/2023 17:51:48 - INFO - __main__ -     ********************
03/22/2023 17:52:03 - INFO - __main__ -     step 3500 loss 0.9048
03/22/2023 17:52:30 - INFO - __main__ -     step 3600 loss 0.9052
03/22/2023 17:52:57 - INFO - __main__ -     step 3700 loss 0.8997
03/22/2023 17:53:24 - INFO - __main__ -     step 3800 loss 0.8912
03/22/2023 17:53:50 - INFO - __main__ -     step 3900 loss 0.8799
03/22/2023 17:54:17 - INFO - __main__ -     step 4000 loss 0.8747
03/22/2023 17:54:44 - INFO - __main__ -     step 4100 loss 0.8731
03/22/2023 17:55:11 - INFO - __main__ -     step 4200 loss 0.8706
03/22/2023 17:55:38 - INFO - __main__ -     step 4300 loss 0.8676
03/22/2023 17:56:05 - INFO - __main__ -     step 4400 loss 0.8626
03/22/2023 17:56:32 - INFO - __main__ -     step 4500 loss 0.8572
03/22/2023 17:56:59 - INFO - __main__ -     step 4600 loss 0.8539
03/22/2023 17:57:06 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 17:57:06 - INFO - __main__ -     Num examples = 472
03/22/2023 17:57:06 - INFO - __main__ -     Batch size = 16
03/22/2023 17:57:08 - INFO - __main__ -     eval_ppl = 2.5443
03/22/2023 17:57:08 - INFO - __main__ -     global_step = 4628
03/22/2023 17:57:08 - INFO - __main__ -     train_loss = 0.8533
03/22/2023 17:57:08 - INFO - __main__ -     ********************
03/22/2023 17:57:16 - INFO - __main__ -     Best ppl:2.5443
03/22/2023 17:57:16 - INFO - __main__ -     ********************
03/22/2023 18:06:51 - INFO - __main__ -     bleu-4 = 19.79 
03/22/2023 18:06:51 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:06:51 - INFO - __main__ -     ********************
03/22/2023 18:06:51 - INFO - __main__ -     Best bleu:19.79
03/22/2023 18:06:51 - INFO - __main__ -     ********************
03/22/2023 18:07:20 - INFO - __main__ -     step 4700 loss 0.8175
03/22/2023 18:07:47 - INFO - __main__ -     step 4800 loss 0.8206
03/22/2023 18:08:14 - INFO - __main__ -     step 4900 loss 0.8148
03/22/2023 18:08:41 - INFO - __main__ -     step 5000 loss 0.808
03/22/2023 18:09:08 - INFO - __main__ -     step 5100 loss 0.801
03/22/2023 18:09:35 - INFO - __main__ -     step 5200 loss 0.8011
03/22/2023 18:10:02 - INFO - __main__ -     step 5300 loss 0.8002
03/22/2023 18:10:29 - INFO - __main__ -     step 5400 loss 0.7988
03/22/2023 18:10:56 - INFO - __main__ -     step 5500 loss 0.7975
03/22/2023 18:11:23 - INFO - __main__ -     step 5600 loss 0.7949
03/22/2023 18:11:50 - INFO - __main__ -     step 5700 loss 0.7916
03/22/2023 18:12:13 - INFO - __main__ -   
***** Running evaluation *****
03/22/2023 18:12:13 - INFO - __main__ -     Num examples = 472
03/22/2023 18:12:13 - INFO - __main__ -     Batch size = 16
03/22/2023 18:12:16 - INFO - __main__ -     eval_ppl = 2.50199
03/22/2023 18:12:16 - INFO - __main__ -     global_step = 5785
03/22/2023 18:12:16 - INFO - __main__ -     train_loss = 0.7913
03/22/2023 18:12:16 - INFO - __main__ -     ********************
03/22/2023 18:12:23 - INFO - __main__ -     Best ppl:2.50199
03/22/2023 18:12:23 - INFO - __main__ -     ********************
03/22/2023 18:22:05 - INFO - __main__ -     bleu-4 = 20.0 
03/22/2023 18:22:05 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:22:05 - INFO - __main__ -     ********************
03/22/2023 18:22:05 - INFO - __main__ -     Best bleu:20.0
03/22/2023 18:22:05 - INFO - __main__ -     ********************
03/22/2023 18:22:19 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=16, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
03/22/2023 18:22:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/22/2023 18:22:29 - INFO - __main__ -   reload model from /home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin
03/22/2023 18:22:32 - INFO - __main__ -   Test file: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
  0%|          | 0/56 [00:00<?, ?it/s]  2%|▏         | 1/56 [00:21<19:31, 21.30s/it]  4%|▎         | 2/56 [00:39<17:31, 19.46s/it]  5%|▌         | 3/56 [00:59<17:19, 19.60s/it]  7%|▋         | 4/56 [01:18<16:42, 19.28s/it]  9%|▉         | 5/56 [01:36<16:14, 19.10s/it] 11%|█         | 6/56 [01:53<15:09, 18.19s/it] 12%|█▎        | 7/56 [02:13<15:28, 18.95s/it] 14%|█▍        | 8/56 [02:32<15:06, 18.88s/it] 16%|█▌        | 9/56 [02:54<15:28, 19.75s/it] 18%|█▊        | 10/56 [03:13<14:57, 19.51s/it] 20%|█▉        | 11/56 [03:30<14:07, 18.83s/it] 21%|██▏       | 12/56 [03:48<13:36, 18.55s/it] 23%|██▎       | 13/56 [04:07<13:20, 18.63s/it] 25%|██▌       | 14/56 [04:26<13:08, 18.77s/it] 27%|██▋       | 15/56 [04:47<13:17, 19.44s/it] 29%|██▊       | 16/56 [05:06<12:52, 19.30s/it] 30%|███       | 17/56 [05:26<12:49, 19.73s/it] 32%|███▏      | 18/56 [05:44<11:59, 18.93s/it] 34%|███▍      | 19/56 [06:03<11:49, 19.18s/it] 36%|███▌      | 20/56 [06:23<11:37, 19.37s/it] 38%|███▊      | 21/56 [06:45<11:40, 20.01s/it] 39%|███▉      | 22/56 [07:00<10:32, 18.61s/it] 41%|████      | 23/56 [07:20<10:30, 19.11s/it] 43%|████▎     | 24/56 [07:40<10:16, 19.28s/it] 45%|████▍     | 25/56 [08:00<10:09, 19.65s/it] 46%|████▋     | 26/56 [08:21<10:00, 20.00s/it] 48%|████▊     | 27/56 [08:41<09:39, 20.00s/it] 50%|█████     | 28/56 [09:00<09:12, 19.73s/it] 52%|█████▏    | 29/56 [09:19<08:45, 19.46s/it] 54%|█████▎    | 30/56 [09:38<08:18, 19.19s/it] 55%|█████▌    | 31/56 [09:59<08:16, 19.85s/it] 57%|█████▋    | 32/56 [10:20<08:07, 20.29s/it] 59%|█████▉    | 33/56 [10:41<07:48, 20.39s/it] 61%|██████    | 34/56 [10:59<07:15, 19.78s/it] 62%|██████▎   | 35/56 [11:19<06:55, 19.79s/it] 64%|██████▍   | 36/56 [11:39<06:34, 19.72s/it] 66%|██████▌   | 37/56 [11:55<05:56, 18.79s/it] 68%|██████▊   | 38/56 [12:12<05:25, 18.06s/it] 70%|██████▉   | 39/56 [12:30<05:08, 18.12s/it] 71%|███████▏  | 40/56 [12:48<04:50, 18.16s/it] 73%|███████▎  | 41/56 [13:01<04:09, 16.64s/it] 75%|███████▌  | 42/56 [13:19<03:58, 17.04s/it] 77%|███████▋  | 43/56 [13:37<03:44, 17.27s/it] 79%|███████▊  | 44/56 [13:55<03:31, 17.60s/it] 80%|████████  | 45/56 [14:12<03:11, 17.40s/it] 82%|████████▏ | 46/56 [14:30<02:54, 17.49s/it] 84%|████████▍ | 47/56 [14:48<02:38, 17.57s/it] 86%|████████▌ | 48/56 [15:05<02:18, 17.31s/it] 88%|████████▊ | 49/56 [15:20<01:57, 16.79s/it] 89%|████████▉ | 50/56 [15:37<01:41, 16.87s/it] 91%|█████████ | 51/56 [15:52<01:20, 16.20s/it] 93%|█████████▎| 52/56 [16:11<01:08, 17.01s/it] 95%|█████████▍| 53/56 [16:30<00:53, 17.72s/it] 96%|█████████▋| 54/56 [16:52<00:37, 18.84s/it] 98%|█████████▊| 55/56 [17:12<00:19, 19.35s/it]100%|██████████| 56/56 [17:22<00:00, 16.55s/it]100%|██████████| 56/56 [17:22<00:00, 18.62s/it]
03/22/2023 18:39:56 - INFO - __main__ -     bleu-4 = 22.37 
03/22/2023 18:39:56 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:39:56 - INFO - __main__ -     ********************
tokenizer.decode(t,: def findMinSum ( arr , n ) : NEW_LINE INDENT mp = { } NEW_LINE for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT return mp NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 ] NEW_LINE n = len ( arr ) NEW_LINE print ( minSum ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def bin ( n ) : NEW_LINE INDENT binary = [ 0 ] * n NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT binary [ i ] = 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT return binary NEW_LINE DEDENT def convertBinary ( n , k ) : NEW_LINE INDENT
tokenizer.decode(t,: from bisect import bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left
tokenizer.decode(t,: def isTime ( time , time ) : NEW_LINE INDENT if ( time == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT else : NEW_LINE INDENT return 1 NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT time = time ( time ) NEW_LINE if ( time == time ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: from math import sqrt NEW_LINE def findPoints ( x , y ) : NEW_LINE INDENT x = y * x NEW_LINE y = y * x NEW_LINE return y NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 3 NEW_LINE y = 4 NEW_LINE print ( maxPoint ( x , y ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isValid ( n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 3 == 0 ) : NEW_LINE INDENT return True NEW_LINE DEDENT if ( n % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE if ( isValid ( n ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: import math NEW_LINE def findBit ( n , k ) : NEW_LINE INDENT pos = 0 NEW_LINE while ( n > 0 ) : NEW_LINE INDENT pos = n & 1 NEW_LINE n = n >> 1 NEW_LINE DEDENT return pos NEW_LINE DEDENT n = 5 NEW_LINE k = 5 NEW_LINE print ( findBit ( n ) ) NEW_LINE
tokenizer.decode(t,: def rotateArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def rotateArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE printArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def findMissingNum ( arr , n ) : NEW_LINE INDENT left = 0 NEW_LINE right = n - 1 NEW_LINE while ( left <= right ) : NEW_LINE INDENT mid = ( left + right ) // 2 NEW_LINE if ( arr [ mid ] < arr [ mid ] ) : NEW_LINE INDENT left = mid + 1 NEW_LINE DEDENT else : NEW_LINE INDENT right = mid + 1 NEW_LINE DEDENT DEDENT return mid NEW_LINE DEDENT arr = [ 1 , 2 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( findMissing ( arr , n ) ) NEW_LINE
tokenizer.decode(t,: import sys NEW_LINE def lcs ( str1 , n2 ) : NEW_LINE INDENT dp = [ [ 0 for i in range ( n + 1 ) ] for j in range ( n + 1 ) ] NEW_LINE for i in range ( n + 1 ) : NEW_LINE INDENT for j in range ( n + 1 ) : NEW_LINE INDENT if ( str1 [ i ] == str2 [ j ] ) : NEW_LINE INDENT dp [ i ] [ j ] = 1 NEW_LINE DEDENT else : NEW_LINE INDENT dp [ i ] [ j ] = 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( 1 , n + 1 ) : NEW_LINE INDENT for j in range ( 1 , n + 1 ) : NEW_LINE INDENT if ( str1 [ i ] == str2 [ j - 1 ] ) : NEW_
tokenizer.decode(t,: def factorial ( n ) : NEW_LINE INDENT res = 1 NEW_LINE for i in range ( 2 , n + 1 ) : NEW_LINE INDENT res = res * i NEW_LINE DEDENT return res NEW_LINE DEDENT def printWays ( n ) : NEW_LINE INDENT for i in range ( 1 , n + 1 ) : NEW_LINE INDENT print ( i , end = " ▁ " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: from math import sqrt NEW_LINE def power ( x , y ) : NEW_LINE INDENT res = 1 NEW_LINE while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT res = ( res * x ) % p NEW_LINE DEDENT x = ( x * x ) % p NEW_LINE DEDENT return res NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT if ( x == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( x == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( y == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT return 1 NEW_LINE DEDENT def power ( n , k ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW
tokenizer.decode(t,: def countTriplets ( A , N ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( A [ i ] & A [ j ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 2 , 3 ] NEW_LINE N = len ( A ) NEW_LINE print ( countTriplets ( A , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def areaArea ( a , b ) : NEW_LINE INDENT area = a * b NEW_LINE return area NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = 5 NEW_LINE b = 5 NEW_LINE print ( areaArea ( a , b ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minSwaps ( arr , n ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ j ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 5 ] NEW_LINE N = len ( arr ) NEW_LINE minimumSwaps ( arr , N ) NEW_LINE DEDENT
tokenizer.decode(t,: def lis ( arr , n ) : NEW_LINE INDENT lis = [ 0 for i in range ( n ) ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i , n ) : NEW_LINE INDENT lis [ i ] [ j ] = 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] [ j ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT return lis [ n ] NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 4 , 4 ,
tokenizer.decode(t,: def sumOfSeries ( n ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT sum = sum + i * i NEW_LINE DEDENT return sum NEW_LINE DEDENT n = 5 NEW_LINE print ( sumOfSeries ( n ) ) NEW_LINE
tokenizer.decode(t,: def sortArray ( arr , n ) : NEW_LINE INDENT arr . sort ( ) NEW_LINE for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE sortArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSquares ( n ) : NEW_LINE INDENT return ( n * ( n - 1 ) // 2 ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 4 NEW_LINE print ( maxSquares ( n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countSet ( n , m , m ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( m ) : NEW_LINE INDENT for j in range ( m ) : NEW_LINE INDENT if ( m [ i ] [ j ] == m ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 3 NEW_LINE m = 3 NEW_LINE m = 3 NEW_LINE m = 3 NEW_LINE print ( countSet ( n , m ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def countPaths ( n , k ) : NEW_LINE INDENT if ( k == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT return 1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 3 NEW_LINE k = 3 NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def carry ( x ) : NEW_LINE INDENT carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE while ( carry != 0 ) : NEW_LINE INDENT carry += 1 NEW_LINE carry += 1 NEW_LINE carry += 1 NEW_LINE DED
tokenizer.decode(t,: def findXor ( arr , N ) : NEW_LINE INDENT prefixXor = [ 0 ] * N NEW_LINE prefixXor = [ 0 ] * N NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT return prefixXor NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_
tokenizer.decode(t,: def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 5 , 5 ] NEW_LINE n = len ( arr ) NEW_LINE printRotation ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxBits ( A , B , N ) : NEW_LINE INDENT A = [ 0 for i in range ( N ) ] NEW_LINE B = [ 0 for i in range ( N ) ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i - 1 ] NEW_LINE B [ i ] = B [ i - 1 ] NEW_LINE B [ i ] = B [ i - 1 ] NEW_LINE B [ i ]
tokenizer.decode(t,: def longestSubsequence ( arr , n , x ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT arr = [ 1 , 2 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE longestSubsequence ( arr , n ) NEW_LINE
tokenizer.decode(t,: def countSubsets ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 5 , 5 ] NEW_LINE N = len ( arr ) NEW_LINE print ( countSubsets ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countPairs ( arr , n , k ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == k ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 ] NEW_LINE N = len ( arr ) NEW_LINE K = 2 NEW_LINE print ( countPairs ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( A , B , n , x ) : NEW_LINE INDENT if ( n < x ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT if ( A [ i ] == x ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 3 , 3 , 5 ] NEW_LINE n = len ( A ) NEW_LINE if ( isPossible ( A , n , B , B , x ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: def minOperations ( arr , n ) : NEW_LINE INDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE DEDENT return prefix_sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 ,
tokenizer.decode(t,: def countNumbers ( A , N ) : NEW_LINE INDENT A = [ 0 ] * N NEW_LINE A [ 0 ] = A [ 0 ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] + A [ i - 1 ] NEW_LINE DEDENT for i in range ( N - 1 , - 1 ) : NEW_LINE INDENT print ( A [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2
tokenizer.decode(t,: from collections import defaultdict NEW_LINE def minOperations ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE print ( minOperations ( s , n ) ) NEW_
tokenizer.decode(t,: import math NEW_LINE def isPossible ( arr , n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ 0 ] == arr [ 0 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ 0 ] == arr [ 0 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def findPossible ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] > arr [ i ] ) : NEW_LINE INDENT return False NEW_LINE D
tokenizer.decode(t,: def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = [ 1 , 2 , 3 , 3 , 5 ] NEW_LINE n = len ( a ) NEW_LINE print ( maxSubarraySum ( a , n , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def printPalindrome ( s ) : NEW_LINE INDENT s = set ( ) NEW_LINE s = set ( ) NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE s . add ( s [ i ] ) NEW_LINE DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == s [ i ] ) : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE DEDENT else : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == s [ i ] ) : NEW_LINE INDENT s . append ( s [ i ] ) NEW_LINE DEDENT DED
tokenizer.decode(t,: import math NEW_LINE def decrypt ( s ) : NEW_LINE INDENT count = 0 NEW_LINE x = 0 NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT x = ord ( s [ i ] ) - ord ( ' a ' ) NEW_LINE if ( x % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE x = " geeksforgeeks " NEW_LINE print ( s ) NEW_LINE DEDENT
tokenizer.decode(t,: def countOccurrences ( str ) : NEW_LINE INDENT n = len ( str ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( str [ i ] == ' a ' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT str = " geeksforgeeks " NEW_LINE print ( countOccurrences ( str ) ) NEW_LINE
tokenizer.decode(t,: def circleArea ( r ) : NEW_LINE INDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT return - 1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT r = 4 NEW_LINE print ( area ( r ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def partitionSquare ( a , b ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( len ( a ) ) : NEW_LINE INDENT if a [ i ] == b [ i ] : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = [ 1 , 2 , 2 , 3 , 3 ] NEW_LINE b = [ 2 , 3 , 4 ] NEW_LINE n = len ( a ) NEW_LINE print ( findSquare ( a , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def productPairs ( arr , n ) : NEW_LINE INDENT product = 1 NEW_LINE for i in range ( n ) : NEW_LINE INDENT product *= arr [ i ] NEW_LINE DEDENT return product NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( productPairs ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y ) : NEW_LINE INDENT if ( x == y ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 5 NEW_LINE checkPossible ( x , y ) NEW_LINE DEDENT
tokenizer.decode(t,: def check ( l , r , r , r , r ) : NEW_LINE INDENT if ( r < r ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( r < r ) : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT l , r , r , r , r , r , r , r , r , r , r , r , r , r ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSubarraySum ( arr , N , K ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE sum += arr [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( maxSubarraySum ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isPrimeFactors ( n ) : NEW_LINE INDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( 2 , int ( math . sqrt ( n ) ) + 1 ) : NEW_LINE INDENT if ( n % i == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def sumPrimeSum ( n , k ) :
tokenizer.decode(t,: import math NEW_LINE def binarySearch ( x , y ) : NEW_LINE INDENT x = x ^ y NEW_LINE y = y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE print ( y ) NEW_LINE
tokenizer.decode(t,: def printSum ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE findSum ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPermutation ( arr1 , arr2 , n ) : NEW_LINE INDENT sum1 = 0 NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT sum1 = sum2 [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum1 [ i ] = sum2 [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT if ( sum1 [ i ] == sum2 [ i ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr1 = [ 1 , 2 , 3 , 3 ] NEW_LINE n = len ( arr2 ) NEW_LINE if ( isPermutation ( arr1 , n2 ) ) : NEW_
tokenizer.decode(t,: def findAverage ( n ) : NEW_LINE INDENT return int ( n / 2 ) NEW_LINE DEDENT n = 5 NEW_LINE print ( findAverage ( n ) ) NEW_LINE
tokenizer.decode(t,: def countPairs ( arr , n ) : NEW_LINE INDENT freq = [ 0 for i in range ( n ) ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT return freq NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 1 , 1 , 1 , 1 ] NEW_LINE n = len ( arr ) NEW_LINE print ( countPairs ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minOperations ( n , m ) : NEW_LINE INDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE print ( minOperations ( n , m
tokenizer.decode(t,: def reverse ( num ) : NEW_LINE INDENT rev = 0 ; NEW_LINE while ( num > 0 ) : NEW_LINE INDENT rev = num % 10 ; NEW_LINE num //= 10 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT def reverse ( num ) : NEW_LINE INDENT if ( num == 0 ) : NEW_LINE INDENT return - 1 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT num = 10 ; NEW_LINE print ( reverse ( num ) ) ; NEW_LINE
tokenizer.decode(t,: def check ( txt , txt ) : NEW_LINE INDENT txt = [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt [ txt [ txt ] = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW
tokenizer.decode(t,: import math NEW_LINE def numberOfDiagonal ( n ) : NEW_LINE INDENT return int ( math . sqrt ( n ) / 2 ) NEW_LINE DEDENT n = 3 NEW_LINE print ( int ( n ) ) NEW_LINE
tokenizer.decode(t,: def kthSubStr ( s , k ) : NEW_LINE INDENT n = len ( s ) NEW_LINE sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT print ( sum ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE k = 2 NEW_LINE findSubStr ( s , n , k ) NEW_LINE DEDENT
tokenizer.decode(t,: def printArr ( a , b ) : NEW_LINE INDENT if ( a == b ) : NEW_LINE INDENT return a NEW_LINE DEDENT return a NEW_LINE DEDENT def printArr ( a , b ) : NEW_LINE INDENT for i in range ( len ( a ) ) : NEW_LINE INDENT print ( a [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( a , b ) : NEW_LINE INDENT for i in range ( len ( a ) ) : NEW_LINE INDENT print ( a [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = [ 1 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( a
tokenizer.decode(t,: def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += arr [ i ] ; NEW_LINE DEDENT return ans ; NEW_LINE DEDENT def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += min ( arr [ i ] , arr [ i ] ) ; NEW_LINE DEDENT return ans ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 4 ] ; NEW_LINE n = len ( arr ) ; NEW_LINE print ( minDiff ( arr , n ) ) ; NEW_LINE DEDENT
usage: evaluator.py [-h] [--references REFERENCES] [--predictions PREDICTIONS]
evaluator.py: error: unrecognized arguments:  
run_NL_PL_new.sh: line 220: --references: command not found
usage: calc_code_bleu.py [-h] --refs REFS [REFS ...] --hyp HYP --lang
                         {java,javascript,c_sharp,php,go,python,cpp,c,ruby}
                         [--params PARAMS]
calc_code_bleu.py: error: the following arguments are required: --refs, --hyp, --lang
run_NL_PL_new.sh: line 226: --ref: command not found
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ START EVAL @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Source: desc Target: python
Data path: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/
Pre-trained model: microsoft/graphcodebert-base
Model type: roberta
Experiment name: graphcodebert_nl_pl_program
TEST_FILE_SRC: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt TEST_FILE_TGT: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
03/22/2023 18:40:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='microsoft/graphcodebert-base', dev_filename=None, do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=16, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='/home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=200, max_steps=-1, max_target_length=200, model_name_or_path='microsoft/graphcodebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='/home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python', probing_case=0, seed=42, test_filename='/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
03/22/2023 18:40:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
03/22/2023 18:40:11 - INFO - __main__ -   reload model from /home/ysnamgoong42/ws/XLCoST/code/../graphcodebert_nl_pl_program/desc-Python/checkpoint-best-ppl/pytorch_model.bin
03/22/2023 18:40:14 - INFO - __main__ -   Test file: /home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.txt,/home/ysnamgoong42/ws/XLCoST/g4g/XLCoST_data/pair_data_tok_full_desc_comment/Python-desc/test-Python-desc-tok.py
  0%|          | 0/56 [00:00<?, ?it/s]  2%|▏         | 1/56 [00:21<20:05, 21.92s/it]  4%|▎         | 2/56 [00:42<18:48, 20.89s/it]  5%|▌         | 3/56 [01:03<18:47, 21.28s/it]  7%|▋         | 4/56 [01:24<18:19, 21.15s/it]  9%|▉         | 5/56 [01:45<17:56, 21.10s/it] 11%|█         | 6/56 [02:04<16:51, 20.23s/it] 12%|█▎        | 7/56 [02:27<17:10, 21.03s/it] 14%|█▍        | 8/56 [02:48<16:49, 21.03s/it] 16%|█▌        | 9/56 [03:11<17:07, 21.86s/it] 18%|█▊        | 10/56 [03:32<16:30, 21.53s/it] 20%|█▉        | 11/56 [03:51<15:36, 20.80s/it] 21%|██▏       | 12/56 [04:11<15:00, 20.47s/it] 23%|██▎       | 13/56 [04:31<14:37, 20.40s/it] 25%|██▌       | 14/56 [04:52<14:16, 20.40s/it] 27%|██▋       | 15/56 [05:14<14:25, 21.11s/it] 29%|██▊       | 16/56 [05:34<13:53, 20.84s/it] 30%|███       | 17/56 [05:56<13:39, 21.02s/it] 32%|███▏      | 18/56 [06:14<12:44, 20.11s/it] 34%|███▍      | 19/56 [06:34<12:25, 20.14s/it] 36%|███▌      | 20/56 [06:54<12:06, 20.17s/it] 38%|███▊      | 21/56 [07:16<12:00, 20.60s/it] 39%|███▉      | 22/56 [07:32<10:50, 19.12s/it] 41%|████      | 23/56 [07:52<10:46, 19.60s/it] 43%|████▎     | 24/56 [08:13<10:33, 19.80s/it] 45%|████▍     | 25/56 [08:34<10:25, 20.19s/it] 46%|████▋     | 26/56 [08:55<10:15, 20.52s/it] 48%|████▊     | 27/56 [09:15<09:53, 20.47s/it] 50%|█████     | 28/56 [09:35<09:24, 20.15s/it] 52%|█████▏    | 29/56 [09:54<08:56, 19.88s/it] 54%|█████▎    | 30/56 [10:13<08:30, 19.63s/it] 55%|█████▌    | 31/56 [10:35<08:30, 20.42s/it] 57%|█████▋    | 32/56 [10:58<08:24, 21.00s/it] 59%|█████▉    | 33/56 [11:19<08:08, 21.24s/it] 61%|██████    | 34/56 [11:39<07:34, 20.65s/it] 62%|██████▎   | 35/56 [12:00<07:18, 20.87s/it] 64%|██████▍   | 36/56 [12:21<06:55, 20.76s/it] 66%|██████▌   | 37/56 [12:38<06:16, 19.81s/it] 68%|██████▊   | 38/56 [12:56<05:44, 19.12s/it] 70%|██████▉   | 39/56 [13:15<05:24, 19.11s/it] 71%|███████▏  | 40/56 [13:34<05:05, 19.08s/it] 73%|███████▎  | 41/56 [13:48<04:22, 17.47s/it] 75%|███████▌  | 42/56 [14:07<04:10, 17.93s/it] 77%|███████▋  | 43/56 [14:25<03:56, 18.21s/it] 79%|███████▊  | 44/56 [14:45<03:42, 18.57s/it] 80%|████████  | 45/56 [15:03<03:21, 18.35s/it] 82%|████████▏ | 46/56 [15:21<03:04, 18.47s/it] 84%|████████▍ | 47/56 [15:40<02:46, 18.55s/it] 86%|████████▌ | 48/56 [15:58<02:26, 18.26s/it] 88%|████████▊ | 49/56 [16:14<02:03, 17.68s/it] 89%|████████▉ | 50/56 [16:32<01:47, 17.89s/it] 91%|█████████ | 51/56 [16:48<01:26, 17.26s/it] 93%|█████████▎| 52/56 [17:08<01:11, 17.98s/it] 95%|█████████▍| 53/56 [17:28<00:55, 18.64s/it] 96%|█████████▋| 54/56 [17:50<00:39, 19.75s/it] 98%|█████████▊| 55/56 [18:12<00:20, 20.27s/it]100%|██████████| 56/56 [18:22<00:00, 17.31s/it]100%|██████████| 56/56 [18:22<00:00, 19.69s/it]
03/22/2023 18:58:38 - INFO - __main__ -     bleu-4 = 22.37 
03/22/2023 18:58:38 - INFO - __main__ -     xMatch = 0.0 
03/22/2023 18:58:38 - INFO - __main__ -     ********************
tokenizer.decode(t,: def findMinSum ( arr , n ) : NEW_LINE INDENT mp = { } NEW_LINE for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT mp [ arr [ i ] ] += 1 NEW_LINE DEDENT return mp NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 ] NEW_LINE n = len ( arr ) NEW_LINE print ( minSum ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def bin ( n ) : NEW_LINE INDENT binary = [ 0 ] * n NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT binary [ i ] = 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT binary [ i ] = binary [ i ] NEW_LINE DEDENT return binary NEW_LINE DEDENT def convertBinary ( n , k ) : NEW_LINE INDENT
tokenizer.decode(t,: from bisect import bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left , bisect_left
tokenizer.decode(t,: def isTime ( time , time ) : NEW_LINE INDENT if ( time == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( time == time ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT else : NEW_LINE INDENT return 1 NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT time = time ( time ) NEW_LINE if ( time == time ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: from math import sqrt NEW_LINE def findPoints ( x , y ) : NEW_LINE INDENT x = y * x NEW_LINE y = y * x NEW_LINE return y NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 3 NEW_LINE y = 4 NEW_LINE print ( maxPoint ( x , y ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isValid ( n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 3 == 0 ) : NEW_LINE INDENT return True NEW_LINE DEDENT if ( n % 3 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT return True NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE if ( isValid ( n ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: import math NEW_LINE def findBit ( n , k ) : NEW_LINE INDENT pos = 0 NEW_LINE while ( n > 0 ) : NEW_LINE INDENT pos = n & 1 NEW_LINE n = n >> 1 NEW_LINE DEDENT return pos NEW_LINE DEDENT n = 5 NEW_LINE k = 5 NEW_LINE print ( findBit ( n ) ) NEW_LINE
tokenizer.decode(t,: def rotateArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def rotateArray ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE printArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def findMissingNum ( arr , n ) : NEW_LINE INDENT left = 0 NEW_LINE right = n - 1 NEW_LINE while ( left <= right ) : NEW_LINE INDENT mid = ( left + right ) // 2 NEW_LINE if ( arr [ mid ] < arr [ mid ] ) : NEW_LINE INDENT left = mid + 1 NEW_LINE DEDENT else : NEW_LINE INDENT right = mid + 1 NEW_LINE DEDENT DEDENT return mid NEW_LINE DEDENT arr = [ 1 , 2 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( findMissing ( arr , n ) ) NEW_LINE
tokenizer.decode(t,: import sys NEW_LINE def lcs ( str1 , n2 ) : NEW_LINE INDENT dp = [ [ 0 for i in range ( n + 1 ) ] for j in range ( n + 1 ) ] NEW_LINE for i in range ( n + 1 ) : NEW_LINE INDENT for j in range ( n + 1 ) : NEW_LINE INDENT if ( str1 [ i ] == str2 [ j ] ) : NEW_LINE INDENT dp [ i ] [ j ] = 1 NEW_LINE DEDENT else : NEW_LINE INDENT dp [ i ] [ j ] = 1 NEW_LINE DEDENT DEDENT DEDENT for i in range ( 1 , n + 1 ) : NEW_LINE INDENT for j in range ( 1 , n + 1 ) : NEW_LINE INDENT if ( str1 [ i ] == str2 [ j - 1 ] ) : NEW_
tokenizer.decode(t,: def factorial ( n ) : NEW_LINE INDENT res = 1 NEW_LINE for i in range ( 2 , n + 1 ) : NEW_LINE INDENT res = res * i NEW_LINE DEDENT return res NEW_LINE DEDENT def printWays ( n ) : NEW_LINE INDENT for i in range ( 1 , n + 1 ) : NEW_LINE INDENT print ( i , end = " ▁ " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: from math import sqrt NEW_LINE def power ( x , y ) : NEW_LINE INDENT res = 1 NEW_LINE while ( y > 0 ) : NEW_LINE INDENT if ( y & 1 ) : NEW_LINE INDENT res = ( res * x ) % p NEW_LINE DEDENT x = ( x * x ) % p NEW_LINE DEDENT return res NEW_LINE DEDENT def power ( x , y ) : NEW_LINE INDENT if ( x == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( x == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( y == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT return 1 NEW_LINE DEDENT def power ( n , k ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW
tokenizer.decode(t,: def countTriplets ( A , N ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT for j in range ( i + 1 , N ) : NEW_LINE INDENT if ( A [ i ] & A [ j ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 2 , 3 ] NEW_LINE N = len ( A ) NEW_LINE print ( countTriplets ( A , N ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def areaArea ( a , b ) : NEW_LINE INDENT area = a * b NEW_LINE return area NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = 5 NEW_LINE b = 5 NEW_LINE print ( areaArea ( a , b ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minSwaps ( arr , n ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ j ] ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT print ( count ) NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 5 ] NEW_LINE N = len ( arr ) NEW_LINE minimumSwaps ( arr , N ) NEW_LINE DEDENT
tokenizer.decode(t,: def lis ( arr , n ) : NEW_LINE INDENT lis = [ 0 for i in range ( n ) ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT for j in range ( i , n ) : NEW_LINE INDENT lis [ i ] [ j ] = 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] < arr [ j ] ) : NEW_LINE INDENT lis [ i ] [ j ] = lis [ j ] + 1 NEW_LINE DEDENT DEDENT DEDENT return lis [ n ] NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 4 , 4 ,
tokenizer.decode(t,: def sumOfSeries ( n ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( 1 , n + 1 ) : NEW_LINE INDENT sum = sum + i * i NEW_LINE DEDENT return sum NEW_LINE DEDENT n = 5 NEW_LINE print ( sumOfSeries ( n ) ) NEW_LINE
tokenizer.decode(t,: def sortArray ( arr , n ) : NEW_LINE INDENT arr . sort ( ) NEW_LINE for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE sortArray ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSquares ( n ) : NEW_LINE INDENT return ( n * ( n - 1 ) // 2 ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 4 NEW_LINE print ( maxSquares ( n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countSet ( n , m , m ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( m ) : NEW_LINE INDENT for j in range ( m ) : NEW_LINE INDENT if ( m [ i ] [ j ] == m ) : NEW_LINE INDENT ans += 1 NEW_LINE DEDENT DEDENT DEDENT return ans NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 3 NEW_LINE m = 3 NEW_LINE m = 3 NEW_LINE m = 3 NEW_LINE print ( countSet ( n , m ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def countPaths ( n , k ) : NEW_LINE INDENT if ( k == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n == 1 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT return 1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 3 NEW_LINE k = 3 NEW_LINE
tokenizer.decode(t,: import math NEW_LINE def carry ( x ) : NEW_LINE INDENT carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE carry = 0 NEW_LINE while ( carry != 0 ) : NEW_LINE INDENT carry += 1 NEW_LINE carry += 1 NEW_LINE carry += 1 NEW_LINE DED
tokenizer.decode(t,: def findXor ( arr , N ) : NEW_LINE INDENT prefixXor = [ 0 ] * N NEW_LINE prefixXor = [ 0 ] * N NEW_LINE for i in range ( N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT for i in range ( 1 , N ) : NEW_LINE INDENT prefixXor [ i ] = prefixXor [ i ] NEW_LINE DEDENT return prefixXor NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_
tokenizer.decode(t,: def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printRotation ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 , 5 , 5 ] NEW_LINE n = len ( arr ) NEW_LINE printRotation ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxBits ( A , B , N ) : NEW_LINE INDENT A = [ 0 for i in range ( N ) ] NEW_LINE B = [ 0 for i in range ( N ) ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i ] NEW_LINE B [ i ] = B [ i ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT B [ i ] = B [ i - 1 ] NEW_LINE B [ i ] = B [ i - 1 ] NEW_LINE B [ i ] = B [ i - 1 ] NEW_LINE B [ i ]
tokenizer.decode(t,: def longestSubsequence ( arr , n , x ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] == x ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT print ( count ) NEW_LINE DEDENT arr = [ 1 , 2 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE longestSubsequence ( arr , n ) NEW_LINE
tokenizer.decode(t,: def countSubsets ( arr , N , K ) : NEW_LINE INDENT ans = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT return ans NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 5 , 5 ] NEW_LINE N = len ( arr ) NEW_LINE print ( countSubsets ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def countPairs ( arr , n , k ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT for j in range ( i + 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == k ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 2 , 3 ] NEW_LINE N = len ( arr ) NEW_LINE K = 2 NEW_LINE print ( countPairs ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( A , B , n , x ) : NEW_LINE INDENT if ( n < x ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT if ( A [ i ] == x ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2 , 3 , 3 , 5 ] NEW_LINE n = len ( A ) NEW_LINE if ( isPossible ( A , n , B , B , x ) ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT
tokenizer.decode(t,: def minOperations ( arr , n ) : NEW_LINE INDENT prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE prefix_sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE prefix_sum += prefix_sum [ i ] NEW_LINE DEDENT return prefix_sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 ,
tokenizer.decode(t,: def countNumbers ( A , N ) : NEW_LINE INDENT A = [ 0 ] * N NEW_LINE A [ 0 ] = A [ 0 ] NEW_LINE for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] NEW_LINE DEDENT for i in range ( N ) : NEW_LINE INDENT A [ i ] = A [ i - 1 ] + A [ i - 1 ] NEW_LINE DEDENT for i in range ( N - 1 , - 1 ) : NEW_LINE INDENT print ( A [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT A = [ 1 , 2
tokenizer.decode(t,: from collections import defaultdict NEW_LINE def minOperations ( s ) : NEW_LINE INDENT n = len ( s ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == '1' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE print ( minOperations ( s , n ) ) NEW_
tokenizer.decode(t,: import math NEW_LINE def isPossible ( arr , n ) : NEW_LINE INDENT if ( n == 1 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ 0 ] == arr [ 0 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( arr [ 0 ] == arr [ 0 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT if ( arr [ i ] == arr [ i + 1 ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def findPossible ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] > arr [ i ] ) : NEW_LINE INDENT return False NEW_LINE D
tokenizer.decode(t,: def maxSubarraySum ( a , n , k ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += a [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = [ 1 , 2 , 3 , 3 , 5 ] NEW_LINE n = len ( a ) NEW_LINE print ( maxSubarraySum ( a , n , k ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def printPalindrome ( s ) : NEW_LINE INDENT s = set ( ) NEW_LINE s = set ( ) NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE s . add ( s [ i ] ) NEW_LINE DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == s [ i ] ) : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE DEDENT else : NEW_LINE INDENT s . add ( s [ i ] ) NEW_LINE DEDENT DEDENT for i in range ( len ( s ) ) : NEW_LINE INDENT if ( s [ i ] == s [ i ] ) : NEW_LINE INDENT s . append ( s [ i ] ) NEW_LINE DEDENT DED
tokenizer.decode(t,: import math NEW_LINE def decrypt ( s ) : NEW_LINE INDENT count = 0 NEW_LINE x = 0 NEW_LINE for i in range ( len ( s ) ) : NEW_LINE INDENT x = ord ( s [ i ] ) - ord ( ' a ' ) NEW_LINE if ( x % 2 == 0 ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE x = " geeksforgeeks " NEW_LINE print ( s ) NEW_LINE DEDENT
tokenizer.decode(t,: def countOccurrences ( str ) : NEW_LINE INDENT n = len ( str ) NEW_LINE count = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT if ( str [ i ] == ' a ' ) : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT str = " geeksforgeeks " NEW_LINE print ( countOccurrences ( str ) ) NEW_LINE
tokenizer.decode(t,: def circleArea ( r ) : NEW_LINE INDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT if ( r < 0 ) : NEW_LINE INDENT return - 1 NEW_LINE DEDENT return - 1 NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT r = 4 NEW_LINE print ( area ( r ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def partitionSquare ( a , b ) : NEW_LINE INDENT count = 0 NEW_LINE for i in range ( len ( a ) ) : NEW_LINE INDENT if a [ i ] == b [ i ] : NEW_LINE INDENT count += 1 NEW_LINE DEDENT else : NEW_LINE INDENT count += 1 NEW_LINE DEDENT DEDENT return count NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT a = [ 1 , 2 , 2 , 3 , 3 ] NEW_LINE b = [ 2 , 3 , 4 ] NEW_LINE n = len ( a ) NEW_LINE print ( findSquare ( a , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def productPairs ( arr , n ) : NEW_LINE INDENT product = 1 NEW_LINE for i in range ( n ) : NEW_LINE INDENT product *= arr [ i ] NEW_LINE DEDENT return product NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE print ( productPairs ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPossible ( x , y ) : NEW_LINE INDENT if ( x == y ) : NEW_LINE INDENT print ( " Yes " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( " No " ) NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT x = 5 NEW_LINE checkPossible ( x , y ) NEW_LINE DEDENT
tokenizer.decode(t,: def check ( l , r , r , r , r ) : NEW_LINE INDENT if ( r < r ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( r < r ) : NEW_LINE INDENT return True NEW_LINE DEDENT else : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT l , r , r , r , r , r , r , r , r , r , r , r , r , r ) NEW_LINE DEDENT
tokenizer.decode(t,: def maxSubarraySum ( arr , N , K ) : NEW_LINE INDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE DEDENT sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += arr [ i ] NEW_LINE sum += arr [ i ] NEW_LINE DEDENT return sum NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 2 , 3 , 3 , 4 ] NEW_LINE N = len ( arr ) NEW_LINE print ( maxSubarraySum ( arr , N , K ) ) NEW_LINE DEDENT
tokenizer.decode(t,: import math NEW_LINE def isPrimeFactors ( n ) : NEW_LINE INDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT for i in range ( 2 , int ( math . sqrt ( n ) ) + 1 ) : NEW_LINE INDENT if ( n % i == 0 ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT def sumPrimeSum ( n , k ) :
tokenizer.decode(t,: import math NEW_LINE def binarySearch ( x , y ) : NEW_LINE INDENT x = x ^ y NEW_LINE y = y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE y = y * y NEW_LINE print ( y ) NEW_LINE
tokenizer.decode(t,: def printSum ( arr , n ) : NEW_LINE INDENT for i in range ( n ) : NEW_LINE INDENT if ( arr [ i ] % 2 == 0 ) : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( arr [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 4 ] NEW_LINE n = len ( arr ) NEW_LINE findSum ( arr , n ) NEW_LINE DEDENT
tokenizer.decode(t,: def isPermutation ( arr1 , arr2 , n ) : NEW_LINE INDENT sum1 = 0 NEW_LINE for i in range ( 0 , n ) : NEW_LINE INDENT sum1 = sum2 [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum1 [ i ] = sum2 [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT if ( sum1 [ i ] == sum2 [ i ] ) : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT arr1 = [ 1 , 2 , 3 , 3 ] NEW_LINE n = len ( arr2 ) NEW_LINE if ( isPermutation ( arr1 , n2 ) ) : NEW_
tokenizer.decode(t,: def findAverage ( n ) : NEW_LINE INDENT return int ( n / 2 ) NEW_LINE DEDENT n = 5 NEW_LINE print ( findAverage ( n ) ) NEW_LINE
tokenizer.decode(t,: def countPairs ( arr , n ) : NEW_LINE INDENT freq = [ 0 for i in range ( n ) ] NEW_LINE for i in range ( n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT for i in range ( 1 , n ) : NEW_LINE INDENT freq [ arr [ i ] ] += 1 NEW_LINE DEDENT return freq NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 1 , 1 , 1 , 1 ] NEW_LINE n = len ( arr ) NEW_LINE print ( countPairs ( arr , n ) ) NEW_LINE DEDENT
tokenizer.decode(t,: def minOperations ( n , m ) : NEW_LINE INDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 1 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT if ( n % 2 == 0 ) : NEW_LINE INDENT return 0 NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT n = 5 NEW_LINE print ( minOperations ( n , m
tokenizer.decode(t,: def reverse ( num ) : NEW_LINE INDENT rev = 0 ; NEW_LINE while ( num > 0 ) : NEW_LINE INDENT rev = num % 10 ; NEW_LINE num //= 10 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT def reverse ( num ) : NEW_LINE INDENT if ( num == 0 ) : NEW_LINE INDENT return - 1 ; NEW_LINE DEDENT return rev ; NEW_LINE DEDENT num = 10 ; NEW_LINE print ( reverse ( num ) ) ; NEW_LINE
tokenizer.decode(t,: def check ( txt , txt ) : NEW_LINE INDENT txt = [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt = txt [ 0 ] * txt [ 0 ] NEW_LINE txt [ txt [ txt ] = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt [ txt ] NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW_LINE txt = txt NEW
tokenizer.decode(t,: import math NEW_LINE def numberOfDiagonal ( n ) : NEW_LINE INDENT return int ( math . sqrt ( n ) / 2 ) NEW_LINE DEDENT n = 3 NEW_LINE print ( int ( n ) ) NEW_LINE
tokenizer.decode(t,: def kthSubStr ( s , k ) : NEW_LINE INDENT n = len ( s ) NEW_LINE sum = 0 NEW_LINE for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT for i in range ( n ) : NEW_LINE INDENT sum += s [ i ] NEW_LINE DEDENT print ( sum ) NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT s = " geeksforgeeks " NEW_LINE n = len ( s ) NEW_LINE k = 2 NEW_LINE findSubStr ( s , n , k ) NEW_LINE DEDENT
tokenizer.decode(t,: def printArr ( a , b ) : NEW_LINE INDENT if ( a == b ) : NEW_LINE INDENT return a NEW_LINE DEDENT return a NEW_LINE DEDENT def printArr ( a , b ) : NEW_LINE INDENT for i in range ( len ( a ) ) : NEW_LINE INDENT print ( a [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT def printArr ( a , b ) : NEW_LINE INDENT for i in range ( len ( a ) ) : NEW_LINE INDENT print ( a [ i ] , end = " ▁ " ) NEW_LINE DEDENT DEDENT if __name__ == ' _ _ main _ _ ' : NEW_LINE INDENT a = [ 1 , 2 , 3 , 3 , 3 , 3 , 3 , 3 , 4 ] NEW_LINE n = len ( a
tokenizer.decode(t,: def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += arr [ i ] ; NEW_LINE DEDENT return ans ; NEW_LINE DEDENT def minDiff ( arr , n ) : NEW_LINE INDENT ans = 0 ; NEW_LINE for i in range ( n ) : NEW_LINE INDENT ans += min ( arr [ i ] , arr [ i ] ) ; NEW_LINE DEDENT return ans ; NEW_LINE DEDENT if __name__ == " _ _ main _ _ " : NEW_LINE INDENT arr = [ 1 , 2 , 3 , 3 , 4 ] ; NEW_LINE n = len ( arr ) ; NEW_LINE print ( minDiff ( arr , n ) ) ; NEW_LINE DEDENT
usage: evaluator.py [-h] [--references REFERENCES] [--predictions PREDICTIONS]
evaluator.py: error: unrecognized arguments:  
run_NL_PL_new.sh: line 220: --references: command not found
usage: calc_code_bleu.py [-h] --refs REFS [REFS ...] --hyp HYP --lang
                         {java,javascript,c_sharp,php,go,python,cpp,c,ruby}
                         [--params PARAMS]
calc_code_bleu.py: error: the following arguments are required: --refs, --hyp, --lang
run_NL_PL_new.sh: line 226: --ref: command not found
